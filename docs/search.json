[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Qingyin Cai",
    "section": "",
    "text": "Here is a list of conferences focused on food, agricultural, and environmental economics. Please check the official websites for updates. Feel free to let me know if you are aware of other great conferences that are not included in this list.\n\n\n\n\n\nA list of small grants for graduate students in general economics and related fields is available on Dr. Anne Byrne’s website.\n\n\n\nThere are many great collections of links that were very helpful during my Ph.D. journey in food, agriculture, and environmental economics.\n\nDr. Aaron Smith at UC Berkeley and UC Davis provides a great gallery on Ag Data.\nDr. Marc Bellemare at the University of Minnesota offers a list of suggested reading on food and agriculture, economic theory, econometrics, and writing.\nDr. Shanjun Li at Cornell University, Dr. Elinor Benami at Virgina Tech, Dr. Tobias Klein at Tilburg University present a list of helpful resources for Ph.D. students."
  },
  {
    "objectID": "resources.html#conferences",
    "href": "resources.html#conferences",
    "title": "Qingyin Cai",
    "section": "",
    "text": "Here is a list of conferences focused on food, agricultural, and environmental economics. Please check the official websites for updates. Feel free to let me know if you are aware of other great conferences that are not included in this list."
  },
  {
    "objectID": "resources.html#grants",
    "href": "resources.html#grants",
    "title": "Qingyin Cai",
    "section": "",
    "text": "A list of small grants for graduate students in general economics and related fields is available on Dr. Anne Byrne’s website."
  },
  {
    "objectID": "resources.html#other-sources",
    "href": "resources.html#other-sources",
    "title": "Qingyin Cai",
    "section": "",
    "text": "There are many great collections of links that were very helpful during my Ph.D. journey in food, agriculture, and environmental economics.\n\nDr. Aaron Smith at UC Berkeley and UC Davis provides a great gallery on Ag Data.\nDr. Marc Bellemare at the University of Minnesota offers a list of suggested reading on food and agriculture, economic theory, econometrics, and writing.\nDr. Shanjun Li at Cornell University, Dr. Elinor Benami at Virgina Tech, Dr. Tobias Klein at Tilburg University present a list of helpful resources for Ph.D. students."
  },
  {
    "objectID": "Lec4_exercise.html",
    "href": "Lec4_exercise.html",
    "title": "Lecture 4 – Exercise Problems",
    "section": "",
    "text": "InstructionsProblemsSolutions\n\n\nUsing Journals from the AER package, examine demand for economics journals (subscriptions at U.S. libraries, year 2000). Read ?Journals first.\nLoad the data with the following code. Check the description of the data with ?Journals.\n\nlibrary(AER)\ndata(\"Journals\")\n# ?Journals\n\nFor anything else, exploring the data is the first step in any data analysis. “Data exploration” section contains the exercise to practice the data manipulation and visualization for descriptive data analysis. Now, it’s your turn to load the package as needed. (I would be happy if you would choose to use the packages we leaned before!)\n\n\nData exploration\n\nList the top 10 journals by citations. Also list the top 10 by price.\nConfirm the data year and show a short sentence/report (from the help page).\nCompute summary stats (mean, median, SD) for: price, pages, citations, and subs.\nMake scatter plots of price vs. citations and price vs. subs using facets function (two panels).\n\nRegression Analysis\nThe goal here is to examine the demand for economics journals. Specifically, we want to estimate the price elasticity of demand for economics journals.\n\nFirst, create the following new variables:\n\n\nciteprice: the price per citation (handle divide-by-zero safely).\n\nage: the number of years since the journal was first published (2000 - foundingyear).\ncharacter_million: number of characters (per issue) in millions.\n\n\nEstimate the following four regression models ((1)~(4)), and report the results in a table.\n\n\\[\\begin{align}\n(1) \\, log(subs) &= \\beta_0 + \\beta_1 log(citeprice) + e \\\\\n(2) \\, log(subs) &= \\beta_0 + \\beta_1 log(citeprice) + \\beta_2 log(age) + e \\\\\n(3) \\, log(subs) &= \\beta_0 + \\beta_1 log(citeprice) + \\beta_2 log(age) + \\beta_3 log(character_million) + e \\\\\n(4) \\, log(subs) &= \\beta_0 + \\beta_1 log(citeprice) + \\beta_2 log(age) + \\beta_3 log(character_million)\n\\end{align}\\]\n\\end{equation}\n\n\n\n# === Load packages === #\nlibrary(AER)\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(modelsummary)\n\n# Data\ndata(\"Journals\")\nsetDT(Journals)\n\n# === Part 1 === #\nJournals[order(-citations)][1:10, .(title, citations, price)]\n\n                                              title citations price\n                                             &lt;char&gt;     &lt;int&gt; &lt;int&gt;\n 1:                        American Economic Review      8999    47\n 2:                                    Econometrica      7943   178\n 3:                    Journal of Political Economy      6697   159\n 4:                  Quarterly Journal of Economics      4138   148\n 5:                              Journal of Finance      3791   226\n 6: Journal of the American Statistical Association      2800   310\n 7:                    Journal of Consumer Research      2762    90\n 8:                  Journal of Financial Economics      2676  1339\n 9:                                Economic Journal      2540   301\n10:                      Journal of Economic Theory      2514  1400\n\nJournals[order(-price)][1:10, .(title, price, citations)]\n\n                             title price citations\n                            &lt;char&gt; &lt;int&gt;     &lt;int&gt;\n 1:              Applied Economics  2120       578\n 2:        Journal of Econometrics  1893      2479\n 3: Journal of Banking and Finance  1539       602\n 4:              Economics Letters  1492       930\n 5:              World Development  1450      1408\n 6:    Journal of Public Economics  1431      1437\n 7:     Journal of Economic Theory  1400      2514\n 8: Journal of Financial Economics  1339      2676\n 9:                Research Policy  1234       922\n10:           Ecological Economics  1170       499\n\n# === Part 2 === #\nhead(Journals[, .(title, subs, price, pages, citations)])\n\n                                                 title  subs price pages\n                                                &lt;char&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1:                   Asian-Pacific Economic Literature    14   123   440\n2:           South African Journal of Economic History    59    20   309\n3:                             Computational Economics    17   443   567\n4: MOCT-MOST Economic Policy in Transitional Economics     2   276   520\n5:                          Journal of Socio-Economics    96   295   791\n6:                                    Labour Economics    15   344   609\n   citations\n       &lt;int&gt;\n1:        21\n2:        22\n3:        22\n4:        22\n5:        24\n6:        24\n\n# === Part 3 === #\nsumstats &lt;- Journals[, .(\n  mean_price = mean(price,  na.rm = TRUE),\n  median_price = median(price, na.rm = TRUE),\n  sd_price = sd(price, na.rm = TRUE),\n  mean_pages = mean(pages,  na.rm = TRUE),\n  median_pages = median(pages, na.rm = TRUE),\n  sd_pages = sd(pages, na.rm = TRUE),\n  mean_cites = mean(citations,  na.rm = TRUE),\n  median_cites = median(citations, na.rm = TRUE),\n  sd_cites = sd(citations, na.rm = TRUE),\n  mean_subs = mean(subs,  na.rm = TRUE),\n  median_subs = median(subs, na.rm = TRUE),\n  sd_subs = sd(subs, na.rm = TRUE)\n)]\nsumstats\n\n   mean_price median_price sd_price mean_pages median_pages sd_pages mean_cites\n        &lt;num&gt;        &lt;num&gt;    &lt;num&gt;      &lt;num&gt;        &lt;num&gt;    &lt;num&gt;      &lt;num&gt;\n1:   417.7222          282 385.8346   827.7444          693 436.8174   647.0556\n   median_cites sd_cites mean_subs median_subs  sd_subs\n          &lt;num&gt;    &lt;num&gt;     &lt;num&gt;       &lt;num&gt;    &lt;num&gt;\n1:        262.5 1182.374  196.8667       122.5 204.5288\n\n# === Part 4 === #\nplot_dt &lt;- melt(\n  Journals[, .(price, citations, subs)],\n  id.vars = \"price\",\n  variable.name = \"yvar\",\n  value.name = \"y\"\n)\n\nggplot(plot_dt, aes(x = price, y = y)) +\n  geom_point() +\n  facet_wrap(~ yvar, scales = \"free_y\") +\n  labs(x = \"Price\", y = \"\", title = \"Price vs. Citations/Subs\") +\n  theme_bw()\n\n\n\n\n\n\n\n# ---------- Regression analysis ----------\n\n# === Part 1 === #\n# Create variables\n# founding year can be in 'foundingyear' or 'start' depending on AER version:\nif (\"foundingyear\" %in% names(Journals)) {\n  Journals[, age := 2000 - foundingyear]\n} else if (\"start\" %in% names(Journals)) {\n  Journals[, age := 2000 - start]\n} else {\n  stop(\"Founding year variable not found. Look for 'foundingyear' or 'start'.\")\n}\n\n# character count per issue (AER::Journals often provides 'char')\nif (\"char\" %in% names(Journals)) {\n  Journals[, character_million := char / 1e6]\n} else if (\"title\" %in% names(Journals)) {\n  # fallback: name length (crude)\n  Journals[, character_million := nchar(as.character(title)) / 1e6]\n} else {\n  stop(\"Neither 'char' nor 'title' found to construct character_million.\")\n}\n\n# price per citation; avoid division-by-zero\nJournals[, citeprice := price / pmax(citations, 1)]\n\n# To safely log, add a small offset where needed:\neps &lt;- 1e-6\nJournals[, l_subs := log(pmax(subs, eps))]\nJournals[, l_citeprice := log(pmax(citeprice, eps))]\nJournals[, l_age := log(pmax(age, 1))]  # age should be &gt;=1\nJournals[, l_char_mil := log(pmax(character_million, eps))]\n\n\n# === Part 2 === #\n# Estimate models\nreg1 &lt;- lm(l_subs ~ l_citeprice, data = Journals)\nreg2 &lt;- lm(l_subs ~ l_citeprice + l_age, data = Journals)\nreg3 &lt;- lm(l_subs ~ l_citeprice + l_age + l_char_mil, data = Journals)\nreg4 &lt;- lm(l_subs ~ l_citeprice + l_age + l_char_mil - 1, data = Journals)  # example w/o intercept per spec\n\n# Report\nmodelsummary(\n  models = list(\"Model (1)\" = reg1,\n                \"Model (2)\" = reg2,\n                \"Model (3)\" = reg3,\n                \"Model (4)\" = reg4),\n  coef_map = c(\n    \"(Intercept)\" = \"Intercept\",\n    \"l_citeprice\" = \"log(Price per citation)\",\n    \"l_age\"       = \"log(Age)\",\n    \"l_char_mil\"  = \"log(Characters per issue, millions)\"\n  ),\n  gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"),\n  stars  = c(\"*\" = .05, \"**\" = .01, \"***\" = .001),\n  output = \"gt\",\n  notes = list(\"Std. Errors in parentheses\")\n)\n\n\n\n\n\n\n\n\nModel (1)\nModel (2)\nModel (3)\nModel (4)\n\n\n\n\nIntercept\n4.766***\n3.396***\n0.931\n\n\n\n\n(0.056)\n(0.300)\n(1.469)\n\n\n\nlog(Price per citation)\n-0.533***\n-0.434***\n-0.439***\n-0.438***\n\n\n\n(0.036)\n(0.040)\n(0.040)\n(0.040)\n\n\nlog(Age)\n\n0.419***\n0.392***\n0.394***\n\n\n\n\n(0.090)\n(0.091)\n(0.091)\n\n\nlog(Characters per issue, millions)\n\n\n-0.242\n-0.329***\n\n\n\n\n\n(0.141)\n(0.029)\n\n\nNum.Obs.\n180\n180\n180\n180\n\n\nR2\n0.557\n0.605\n0.612\n0.979\n\n\nR2 Adj.\n0.555\n0.601\n0.605\n0.979\n\n\n\n* p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\nStd. Errors in parentheses"
  },
  {
    "objectID": "Lec4_exercise.html#exercise-1-demand-for-economics-journal-stock-and-watson-2017-p336-337",
    "href": "Lec4_exercise.html#exercise-1-demand-for-economics-journal-stock-and-watson-2017-p336-337",
    "title": "Lecture 4 – Exercise Problems",
    "section": "",
    "text": "InstructionsProblemsSolutions\n\n\nUsing Journals from the AER package, examine demand for economics journals (subscriptions at U.S. libraries, year 2000). Read ?Journals first.\nLoad the data with the following code. Check the description of the data with ?Journals.\n\nlibrary(AER)\ndata(\"Journals\")\n# ?Journals\n\nFor anything else, exploring the data is the first step in any data analysis. “Data exploration” section contains the exercise to practice the data manipulation and visualization for descriptive data analysis. Now, it’s your turn to load the package as needed. (I would be happy if you would choose to use the packages we leaned before!)\n\n\nData exploration\n\nList the top 10 journals by citations. Also list the top 10 by price.\nConfirm the data year and show a short sentence/report (from the help page).\nCompute summary stats (mean, median, SD) for: price, pages, citations, and subs.\nMake scatter plots of price vs. citations and price vs. subs using facets function (two panels).\n\nRegression Analysis\nThe goal here is to examine the demand for economics journals. Specifically, we want to estimate the price elasticity of demand for economics journals.\n\nFirst, create the following new variables:\n\n\nciteprice: the price per citation (handle divide-by-zero safely).\n\nage: the number of years since the journal was first published (2000 - foundingyear).\ncharacter_million: number of characters (per issue) in millions.\n\n\nEstimate the following four regression models ((1)~(4)), and report the results in a table.\n\n\\[\\begin{align}\n(1) \\, log(subs) &= \\beta_0 + \\beta_1 log(citeprice) + e \\\\\n(2) \\, log(subs) &= \\beta_0 + \\beta_1 log(citeprice) + \\beta_2 log(age) + e \\\\\n(3) \\, log(subs) &= \\beta_0 + \\beta_1 log(citeprice) + \\beta_2 log(age) + \\beta_3 log(character_million) + e \\\\\n(4) \\, log(subs) &= \\beta_0 + \\beta_1 log(citeprice) + \\beta_2 log(age) + \\beta_3 log(character_million)\n\\end{align}\\]\n\\end{equation}\n\n\n\n# === Load packages === #\nlibrary(AER)\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(modelsummary)\n\n# Data\ndata(\"Journals\")\nsetDT(Journals)\n\n# === Part 1 === #\nJournals[order(-citations)][1:10, .(title, citations, price)]\n\n                                              title citations price\n                                             &lt;char&gt;     &lt;int&gt; &lt;int&gt;\n 1:                        American Economic Review      8999    47\n 2:                                    Econometrica      7943   178\n 3:                    Journal of Political Economy      6697   159\n 4:                  Quarterly Journal of Economics      4138   148\n 5:                              Journal of Finance      3791   226\n 6: Journal of the American Statistical Association      2800   310\n 7:                    Journal of Consumer Research      2762    90\n 8:                  Journal of Financial Economics      2676  1339\n 9:                                Economic Journal      2540   301\n10:                      Journal of Economic Theory      2514  1400\n\nJournals[order(-price)][1:10, .(title, price, citations)]\n\n                             title price citations\n                            &lt;char&gt; &lt;int&gt;     &lt;int&gt;\n 1:              Applied Economics  2120       578\n 2:        Journal of Econometrics  1893      2479\n 3: Journal of Banking and Finance  1539       602\n 4:              Economics Letters  1492       930\n 5:              World Development  1450      1408\n 6:    Journal of Public Economics  1431      1437\n 7:     Journal of Economic Theory  1400      2514\n 8: Journal of Financial Economics  1339      2676\n 9:                Research Policy  1234       922\n10:           Ecological Economics  1170       499\n\n# === Part 2 === #\nhead(Journals[, .(title, subs, price, pages, citations)])\n\n                                                 title  subs price pages\n                                                &lt;char&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1:                   Asian-Pacific Economic Literature    14   123   440\n2:           South African Journal of Economic History    59    20   309\n3:                             Computational Economics    17   443   567\n4: MOCT-MOST Economic Policy in Transitional Economics     2   276   520\n5:                          Journal of Socio-Economics    96   295   791\n6:                                    Labour Economics    15   344   609\n   citations\n       &lt;int&gt;\n1:        21\n2:        22\n3:        22\n4:        22\n5:        24\n6:        24\n\n# === Part 3 === #\nsumstats &lt;- Journals[, .(\n  mean_price = mean(price,  na.rm = TRUE),\n  median_price = median(price, na.rm = TRUE),\n  sd_price = sd(price, na.rm = TRUE),\n  mean_pages = mean(pages,  na.rm = TRUE),\n  median_pages = median(pages, na.rm = TRUE),\n  sd_pages = sd(pages, na.rm = TRUE),\n  mean_cites = mean(citations,  na.rm = TRUE),\n  median_cites = median(citations, na.rm = TRUE),\n  sd_cites = sd(citations, na.rm = TRUE),\n  mean_subs = mean(subs,  na.rm = TRUE),\n  median_subs = median(subs, na.rm = TRUE),\n  sd_subs = sd(subs, na.rm = TRUE)\n)]\nsumstats\n\n   mean_price median_price sd_price mean_pages median_pages sd_pages mean_cites\n        &lt;num&gt;        &lt;num&gt;    &lt;num&gt;      &lt;num&gt;        &lt;num&gt;    &lt;num&gt;      &lt;num&gt;\n1:   417.7222          282 385.8346   827.7444          693 436.8174   647.0556\n   median_cites sd_cites mean_subs median_subs  sd_subs\n          &lt;num&gt;    &lt;num&gt;     &lt;num&gt;       &lt;num&gt;    &lt;num&gt;\n1:        262.5 1182.374  196.8667       122.5 204.5288\n\n# === Part 4 === #\nplot_dt &lt;- melt(\n  Journals[, .(price, citations, subs)],\n  id.vars = \"price\",\n  variable.name = \"yvar\",\n  value.name = \"y\"\n)\n\nggplot(plot_dt, aes(x = price, y = y)) +\n  geom_point() +\n  facet_wrap(~ yvar, scales = \"free_y\") +\n  labs(x = \"Price\", y = \"\", title = \"Price vs. Citations/Subs\") +\n  theme_bw()\n\n\n\n\n\n\n\n# ---------- Regression analysis ----------\n\n# === Part 1 === #\n# Create variables\n# founding year can be in 'foundingyear' or 'start' depending on AER version:\nif (\"foundingyear\" %in% names(Journals)) {\n  Journals[, age := 2000 - foundingyear]\n} else if (\"start\" %in% names(Journals)) {\n  Journals[, age := 2000 - start]\n} else {\n  stop(\"Founding year variable not found. Look for 'foundingyear' or 'start'.\")\n}\n\n# character count per issue (AER::Journals often provides 'char')\nif (\"char\" %in% names(Journals)) {\n  Journals[, character_million := char / 1e6]\n} else if (\"title\" %in% names(Journals)) {\n  # fallback: name length (crude)\n  Journals[, character_million := nchar(as.character(title)) / 1e6]\n} else {\n  stop(\"Neither 'char' nor 'title' found to construct character_million.\")\n}\n\n# price per citation; avoid division-by-zero\nJournals[, citeprice := price / pmax(citations, 1)]\n\n# To safely log, add a small offset where needed:\neps &lt;- 1e-6\nJournals[, l_subs := log(pmax(subs, eps))]\nJournals[, l_citeprice := log(pmax(citeprice, eps))]\nJournals[, l_age := log(pmax(age, 1))]  # age should be &gt;=1\nJournals[, l_char_mil := log(pmax(character_million, eps))]\n\n\n# === Part 2 === #\n# Estimate models\nreg1 &lt;- lm(l_subs ~ l_citeprice, data = Journals)\nreg2 &lt;- lm(l_subs ~ l_citeprice + l_age, data = Journals)\nreg3 &lt;- lm(l_subs ~ l_citeprice + l_age + l_char_mil, data = Journals)\nreg4 &lt;- lm(l_subs ~ l_citeprice + l_age + l_char_mil - 1, data = Journals)  # example w/o intercept per spec\n\n# Report\nmodelsummary(\n  models = list(\"Model (1)\" = reg1,\n                \"Model (2)\" = reg2,\n                \"Model (3)\" = reg3,\n                \"Model (4)\" = reg4),\n  coef_map = c(\n    \"(Intercept)\" = \"Intercept\",\n    \"l_citeprice\" = \"log(Price per citation)\",\n    \"l_age\"       = \"log(Age)\",\n    \"l_char_mil\"  = \"log(Characters per issue, millions)\"\n  ),\n  gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"),\n  stars  = c(\"*\" = .05, \"**\" = .01, \"***\" = .001),\n  output = \"gt\",\n  notes = list(\"Std. Errors in parentheses\")\n)\n\n\n\n\n\n\n\n\nModel (1)\nModel (2)\nModel (3)\nModel (4)\n\n\n\n\nIntercept\n4.766***\n3.396***\n0.931\n\n\n\n\n(0.056)\n(0.300)\n(1.469)\n\n\n\nlog(Price per citation)\n-0.533***\n-0.434***\n-0.439***\n-0.438***\n\n\n\n(0.036)\n(0.040)\n(0.040)\n(0.040)\n\n\nlog(Age)\n\n0.419***\n0.392***\n0.394***\n\n\n\n\n(0.090)\n(0.091)\n(0.091)\n\n\nlog(Characters per issue, millions)\n\n\n-0.242\n-0.329***\n\n\n\n\n\n(0.141)\n(0.029)\n\n\nNum.Obs.\n180\n180\n180\n180\n\n\nR2\n0.557\n0.605\n0.612\n0.979\n\n\nR2 Adj.\n0.555\n0.601\n0.605\n0.979\n\n\n\n* p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\nStd. Errors in parentheses"
  },
  {
    "objectID": "Lec4_exercise.html#exercise-2-analysis-of-the-test-score-dataset-stock-and-watson-2017-chapter-7.6",
    "href": "Lec4_exercise.html#exercise-2-analysis-of-the-test-score-dataset-stock-and-watson-2017-chapter-7.6",
    "title": "Lecture 4 – Exercise Problems",
    "section": "2 Exercise 2: Analysis of the Test Score Dataset (Stock and Watson (2017), Chapter 7.6)",
    "text": "2 Exercise 2: Analysis of the Test Score Dataset (Stock and Watson (2017), Chapter 7.6)\n\nInstructionsProblemsSolutions\n\n\nUsing the CASchools dataset from the AER package, let’s do some regression analysis to examine the effects on test scores of the student-teacher ratio. The dataset contains data on test performance, school characteristics and student demographic backgrounds for school districts in California.\nFirst, let’s load the data. See ?CASchools for the description of variables in the dataset.\n\n# === Loading Data === #\ndata(\"CASchools\")\n\n\n\n\nCreate the follwing new variables:\n\n\nstratio: student-teacher ratio (students/teachers)\nscore: the average of math and reading scores ((math + read)/2)\n\n\nUsing datasummary function, generate a summary table of key descriptive statistics for the CASchools dataset, including variables like score, stratio, english, and lunch, calworks.\nUsing ggplot functions, Create scanter plots of test scores (score) against the percentage of English language learners (english), percentage qualifying for reduced-price lunch (lunch), and percentage qualifying for income assistance (calworks). (It would be nice if you could use the facet_wrap() function to show them at once.)\nEstimate the following five regression models and report the results in a table.\n\n\\[\\begin{align}\n(1) \\, score &= \\beta_0 + \\beta_1 stratio + e \\\\\n(2) \\, score &= \\beta_0 + \\beta_1 stratio + \\beta_2 english + e \\\\\n(3) \\, score &= \\beta_0 + \\beta_1 stratio + \\beta_2 english + \\beta_3 lunch + e \\\\\n(4) \\, score &= \\beta_0 + \\beta_1 stratio + \\beta_2 english + \\beta_3 calworks + e \\\\\n(5) \\, score &= \\beta_0 + \\beta_1 stratio + \\beta_2 english + \\beta_3 lunch + \\beta_4 calworks + e \\\\\n\\end{align}\\]\n\n\n\n# === Load package === #\n# This is redundant but I am loading the same packages we already used before just for the purpose of showing which package I am using to work on this problem. Note than you need to you load the package only once in your current R session.\n\nlibrary(AER)\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(modelsummary)\n\n# === Data === #\ndata(CASchools)\nsetDT(CASchools)\n\n# === Part 1 === #\nCASchools[,`:=`(\n  stratio = students/teachers,\n  score = (math + read)/2\n  )]\n\n# === Part 2 === #\ndatasummary(\n  formula = score + stratio + english + lunch + calworks ~ Mean + SD + Min + Max,\n  data = CASchools,\n  )\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Mean\n                SD\n                Min\n                Max\n              \n        \n        \n        \n                \n                  score   \n                  654.16\n                  19.05\n                  605.55\n                  706.75\n                \n                \n                  stratio \n                  19.64 \n                  1.89 \n                  14.00 \n                  25.80 \n                \n                \n                  english \n                  15.77 \n                  18.29\n                  0.00  \n                  85.54 \n                \n                \n                  lunch   \n                  44.71 \n                  27.12\n                  0.00  \n                  100.00\n                \n                \n                  calworks\n                  13.25 \n                  11.45\n                  0.00  \n                  78.99 \n                \n        \n      \n    \n\n\n# === Part 3 === #\nlong2 &lt;- melt(\n  CASchools[, .(score, english, lunch, calworks)],\n  id.vars = \"score\",\n  variable.name = \"xvar\",\n  value.name = \"x\"\n)\n\nggplot(long2, aes(x = x, y = score)) +\n  geom_point() +\n  facet_wrap(~ xvar, scales = \"free_x\") +\n  labs(x = \"\", y = \"Score\", title = \"Score vs. Demographic/Program Shares\") +\n  theme_bw()\n\n\n\n\n\n\n\n# === Part 4 === #\nrge1 &lt;- lm(score ~ stratio, data = CASchools)\nrge2 &lt;- lm(score ~ stratio + english, data = CASchools)\nreg3 &lt;- lm(score ~ stratio + english + lunch, data = CASchools)\nreg4 &lt;- lm(score ~ stratio + english + calworks, data = CASchools)\nreg5 &lt;- lm(score ~ stratio + english + lunch + calworks, data = CASchools)\n\nmodelsummary(\n  models = list(rge1, rge2, reg3, reg4, reg5),\n  stars  =  c(\"*\" = .05, \"**\" = .01, \"***\" = .001), \n  coef_map = c(\n    \"stratio\" = \"Student-teacher ratio\",\n    \"english\" = \"Percent Englisch learners\",\n    \"lunch\" = \"Percent eligible for subsidiezxed lunch\",\n    \"calworks\" = \"Percent qualifying for CalWorks.\",\n    \"(Intercept)\" = \"Intercept\"\n    ),\n  gof_map = c(\"nobs\", \"r.squared\",  \"adj.r.squared\"),\n  fmt = 2,\n  notes = list(\"Std. Errors in parentheses\")\n)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n                (3)\n                (4)\n                (5)\n              \n        \n        * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nStd. Errors in parentheses\n        \n                \n                  Student-teacher ratio                  \n                  -2.28*** \n                  -1.10**  \n                  -1.00*** \n                  -1.31*** \n                  -1.01*** \n                \n                \n                                                         \n                  (0.48)   \n                  (0.38)   \n                  (0.24)   \n                  (0.31)   \n                  (0.24)   \n                \n                \n                  Percent Englisch learners              \n                           \n                  -0.65*** \n                  -0.12*** \n                  -0.49*** \n                  -0.13*** \n                \n                \n                                                         \n                           \n                  (0.04)   \n                  (0.03)   \n                  (0.03)   \n                  (0.03)   \n                \n                \n                  Percent eligible for subsidiezxed lunch\n                           \n                           \n                  -0.55*** \n                           \n                  -0.53*** \n                \n                \n                                                         \n                           \n                           \n                  (0.02)   \n                           \n                  (0.03)   \n                \n                \n                  Percent qualifying for CalWorks.       \n                           \n                           \n                           \n                  -0.79*** \n                  -0.05    \n                \n                \n                                                         \n                           \n                           \n                           \n                  (0.05)   \n                  (0.06)   \n                \n                \n                  Intercept                              \n                  698.93***\n                  686.03***\n                  700.15***\n                  698.00***\n                  700.39***\n                \n                \n                                                         \n                  (9.47)   \n                  (7.41)   \n                  (4.69)   \n                  (6.02)   \n                  (4.70)   \n                \n                \n                  Num.Obs.                               \n                  420      \n                  420      \n                  420      \n                  420      \n                  420      \n                \n                \n                  R2                                     \n                  0.051    \n                  0.426    \n                  0.775    \n                  0.629    \n                  0.775    \n                \n                \n                  R2 Adj.                                \n                  0.049    \n                  0.424    \n                  0.773    \n                  0.626    \n                  0.773"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Qingyin Cai",
    "section": "",
    "text": "Welcome to my website!\nI’m a PhD candidate in the Department of Applied Economics at the University of Minnesota. My fields of interest include food and agricultural economics, consumer economics, empirical IO, and environmental economics.\nMy research addresses complex and topical economic problems in food and agricultural markets, focusing on the impact of climate shocks on agrifood systems and farmland consolidation, as well as the effects of food price inflation on retail landscapes and consumer welfare.\nHere is the latest version of my CV.\nEmail: cai00154@umn.edu"
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "Qingyin Cai",
    "section": "",
    "text": "Welcome to my website!\nI’m a PhD candidate in the Department of Applied Economics at the University of Minnesota. My fields of interest include food and agricultural economics, consumer economics, empirical IO, and environmental economics.\nMy research addresses complex and topical economic problems in food and agricultural markets, focusing on the impact of climate shocks on agrifood systems and farmland consolidation, as well as the effects of food price inflation on retail landscapes and consumer welfare.\nHere is the latest version of my CV.\nEmail: cai00154@umn.edu"
  },
  {
    "objectID": "Lec2.html#section",
    "href": "Lec2.html#section",
    "title": "Day 2: Data wrangling with data.table",
    "section": "",
    "text": "Learning Objectives\n\nUse basic data wrangling skills with the data.table package\n\nLearn how to use the %&gt;% operator from the magrittr package (Optional)\n\n\n\n Reference\n\n\nIntroduction to data.table\n\n\nEfficient reshaping using data.table\n\nR for Data Science, Ch18: Pipes"
  },
  {
    "objectID": "Lec2.html#todays-outline",
    "href": "Lec2.html#todays-outline",
    "title": "Day 2: Data wrangling with data.table",
    "section": "\n Today’s outline:",
    "text": "Today’s outline:\n\n\nData manipulation with data.table\n\nWhat is data.table?\ndata.table syntax\nSubset rows\nSelect columns\nCompute on columns\nCreate a new column\nPerform aggregations by group\nReshape datasets\nMerge datasets\n\n\n%&gt;% operator (optional)\nAfter-class Exercise Problems\nAppendix"
  },
  {
    "objectID": "Lec2.html#what-is-data-table",
    "href": "Lec2.html#what-is-data-table",
    "title": "Day 2: Data wrangling with data.table",
    "section": "What is data.table?",
    "text": "What is data.table?\n\n\nWhat is it?\nBefore Starting\n\n\n\n\n\ndata.table is a package in R that provides an enhanced version of data.frame.\n\nIt is designed to be fast and memory efficient.\n\n\n\n\n\nThere is another package called dplyr that is also popular for data wrangling. But data.table is much faster than dplyr particularly for large-scale data manipulation tasks.\n\nSee this for the speed comparison of dplyr and data.table.\n\n\nThis website compares dplyr vs data.table side by side. If you already know dplyr syntax, this website would be helpful to understand data.table syntax.\n\n\n\n\n\n\nLet’s use flights data, which is obtained from nycflights13.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nConverting to data.table.\n\n\nTo use the special features of the data.table package, the data must be in the data.table class.\nYou can convert a data.frame (or tibble) into a data.table by using the setDT() function.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec2.html#syntax-data-table",
    "href": "Lec2.html#syntax-data-table",
    "title": "Day 2: Data wrangling with data.table",
    "section": "data.table syntax",
    "text": "data.table syntax\nThe general form of data.table syntax is\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\ni: choose rows (filtering or subsetting)\n\nj: choose or transform columns (summaries, calculations, or selecting variables)\n\nby: group by variables (do the calculation in j separately for each group)\n\n\nSimply put,\nStart with a data.table DT. First pick rows using i, then work on columns with j, and if needed, repeat that operation for each group defined by by."
  },
  {
    "objectID": "Lec2.html#section-1",
    "href": "Lec2.html#section-1",
    "title": "Day 2: Data wrangling with data.table",
    "section": "",
    "text": "Using data.table syntax, we will see how to:\n\nsubset rows\nselect columns, compute on the selected columns, create a new column\nperform aggregations by group"
  },
  {
    "objectID": "Lec2.html#subset-rows",
    "href": "Lec2.html#subset-rows",
    "title": "Day 2: Data wrangling with data.table",
    "section": "1. Subset Rows",
    "text": "1. Subset Rows\n\n\nBasics\nIn-class Exercise\n\n\n\n\n\ndata.table syntax: DT[i, j, by]\n\nTo subset rows, put a condition on a column inside i.\n\nExample: DT[colA == \"value\", ] selects rows where column colA equals \"value\".\n\n\n\nExample\nSubset rows where carrier is \"AA\" (American Airlines):\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nWhat happens here?\n\n\ni: selects rows where carrier == \"AA\"\n\n\nj: no action (all columns)\n\nby: no action (no grouping)\n\n\n\n\n\n\n\nQuestions\nAnswers\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec2.html#other-row-related-tasks",
    "href": "Lec2.html#other-row-related-tasks",
    "title": "Day 2: Data wrangling with data.table",
    "section": "Other row-related tasks",
    "text": "Other row-related tasks\nThe key idea: all tasks related to rows are done inside i.\n\nExample\n\n\nFilter rows\nSelect by row number\nRemove rows\nSort rows\n\n\n\nSelect flights where carrier is \"AA\":\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nReturn the first 5 rows:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nExclude rows 1 to 10:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nSort by month (ascending) and then day (descending):\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec2.html#select-columns",
    "href": "Lec2.html#select-columns",
    "title": "Day 2: Data wrangling with data.table",
    "section": "2. Select Columns",
    "text": "2. Select Columns\n\n\nBasics\nMultiple columns\nIn-class exercise\n\n\n\n\n\ndata.table syntax: DT[i, j, by]\n\nTo select columns, use the j argument\n\nExample:\nSuppose we want to select dep_time column. Since we are not subsetting rows, we leave the i argument blank.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nIf we wrap variables (column names) in list(), the result will be returned as a data.table.\n\n\n.() is simply shorthand for list() in data.table syntax.\n\n\nImportant: In data.table, each column is internally stored as a list. When you use .() (or list()) in the j expression, each element of that list becomes a column in the resulting data.table.\n\n\n\n\nYou can select multiple columns just like you did to select a single column.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nQuestions\nAnswers\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec2.html#compute-on-columns",
    "href": "Lec2.html#compute-on-columns",
    "title": "Day 2: Data wrangling with data.table",
    "section": "3. Compute on Columns",
    "text": "3. Compute on Columns\n\nBasics\n\n\ndata.table syntax: DT[i, j, by]\n\n\nj not only allows you to select columns but also to compute on columns\n\nExample\nLet’s count the number of trips which have had total delay &lt; 0 (i.e., total day = dep_delay + arr_delay).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWhat happens in this code?\n\n\ni: no action (all rows are used)\n\n\nj: takes the sum of the logical vector arr_delay + dep_delay &lt; 0\n\n\nby: no action (no grouping)\n\nNote: Since we skip the i expression, we must include a comma before the j expression."
  },
  {
    "objectID": "Lec2.html#compute-on-columns-of-the-subsetted-rows",
    "href": "Lec2.html#compute-on-columns-of-the-subsetted-rows",
    "title": "Day 2: Data wrangling with data.table",
    "section": "3. Compute on Columns of the Subsetted Rows",
    "text": "3. Compute on Columns of the Subsetted Rows\n\n\nBasics\nMultiple outputs\nIn-class exercise\n\n\n\n\n\ndata.table syntax: DT[i, j, by]\n\nUsing i and j expressions together, you can perform calculations on the selected columns of the subsetted rows.\n\n\nExample\nHow many flights departed from “JFK” airport in the month of June?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nWhat happens in this code?\n\n\ni : to select rows where origin airport equals “JFK”, and month equals 6.\n\nj : to count the number of rows in the subsetted data.\n\nby : no action (no grouping)\n\n\n\n\nYou can assign names to the values you calculate in j.\nRecall that .() is a shorthand for list() in data.table syntax. You can name each element inside .() just like naming elements in a regular list.\n\n\nExample\nCount how many flights departed from JFK airport in June. For those flights, calculate the average departure delay (dep_delay).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nQuestions\nAnswers\n\n\n\n\nFind the average arrival delay and the average departure delay for flights that departed from JFK in August.\n\n\nHint:\n\nUse the columns: origin, month, arr_delay, dep_delay\n\nUse the mean() function to calculate averages\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nFind the average arrival delay and the average departure delay for flights that departed from JFK in August.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec2.html#create-a-new-column",
    "href": "Lec2.html#create-a-new-column",
    "title": "Day 2: Data wrangling with data.table",
    "section": "4. Create a New Column",
    "text": "4. Create a New Column\n\n\nBasics\nExample\nMultiple new columns\nNote\nUpdate with a condition\nIn-class exercise\n\n\n\n\n\ndata.table syntax: DT[i, j, by]\n\nIn j expression, you can add or update a column in the data table using the := operator.\n\nThink of := as a special assignment operator inside data.table. It modifies the data table by reference (changes the original table without making a copy).\n\n\n\n\nSyntax\n# === Add one column === #\nDT[, \"new_column_name\" := .(valueA)]\n\n# or you can drop the quotes and `.()` for convenience\nDT[, new_column_name := valueA]\n\n\nUsing the dataset below, create a new column c that is the sum of columns a and b.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nImportant Rule\nThe operator := creates new columns by updating the data in place (by reference). This means the original data table is directly modified.\n\n\nHere is how you define multiple variables at the same time.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nThe := operator in data.table does not allow you to reference newly created or modified columns within the same [ expression.\nIf you want to use a new column in another calculation, you need a second [ step.\n\nExample\n\nLet’s create two new columns: (1) c by adding a and b, and (2) d by dividing c by a.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nUsing i and j expressions together, you can change the column values for rows that satisfy certain conditions.\n\nExample:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nKeeping the original data:\n\nIf you want to keep the original dataset unchanged, use the data.table::copy() function to create a duplicate.\nThe object created with copy() is completely independent: changes to one will not affect the other.\n\n\n\n\n\nQuestions\nAnswers\n\n\n\nCreate two new columns in the flights data:\n\n\ntotal_delay: the sum of dep_delay and arr_delay.\n\nspeed: the ratio of distance to air_time (i.e, distance/air_time.)\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec2.html#perform-aggregations-by-group",
    "href": "Lec2.html#perform-aggregations-by-group",
    "title": "Day 2: Data wrangling with data.table",
    "section": "5. Perform Aggregations by Group (Grouped Operations)",
    "text": "5. Perform Aggregations by Group (Grouped Operations)\n\n\nBasics\nGroup by multiple columns\nGrouped operations for select observations\nIn-class exercise\n\n\n\n\n\ndata.table syntax: DT[i, j, by]\n\nTo perform grouped operations, use by argument.\n\nSyntax\n\nDT[, .(new_column = function(column)), by = .(group_variable)]\n\n\nExample: Let’s find the number of flights by origin.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nWhat happens in this code?\n\n\ni: no action (all rows)\n\nj: count the number of rows in each group defined by by argument\n\nby: group the data by origin\n\n\n\n\nNothing special. Just provide multiple columns to by argument.\n\nExample: Find the average time of departure delay and arrival delay by carrier and origin.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nBy combining the i argument with by, you can perform grouped operations on a subset of rows.\n\nExample 1: Get the number of flights for each origin airport for carrier code “AA” (American Airlines).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWhat happens in this code? - i: subset rows where carrier is “AA” - j: count the number of rows in each group defined by by argument - by: group the data by origin\n\nExample 2: Find the number of flights by origin and month for carrier code “AA” (American Airlines).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nQuestions\nAnswers\n\n\n\n\nFor each month and each carrier, calculate the total number of flights, average departure delay, and average arrival delay.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n(Optional) Define seasons (Winter: Dec-Feb, Spring: Mar-May, Summer: Jun-Aug, Fall: Sep-Nov) and summarize the total number of flights, average departure delay, and average arrival delay for each season and each carrier.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nFor each month and each carrier, calculate the total number of flights, average departure delay, and average arrival delay.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n(Optional) Define seasons (Winter: Dec-Feb, Spring: Mar-May, Summer: Jun-Aug, Fall: Sep-Nov) and summarize the total number of flights, average departure delay, and average arrival delay for each season and each carrier.\n\nNote: I used fcase() function of data.table package to define seasons. It is useful when you want to define a variable that takes different values based on conditions.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec2.html#summary",
    "href": "Lec2.html#summary",
    "title": "Day 2: Data wrangling with data.table",
    "section": "Summary",
    "text": "Summary\nSo far, we have covered the basic operations in the data.table package.\nFocus on these key ideas:\n\nThe general syntax is DT[i, j, by]:\n\n\ni → rows\n\n\nj → columns\n\n\nby → groups\n\n\nUse i for anything related to rows.\n\nExample: filter rows with conditions.\n\n\nUse j for anything related to columns.\n\nExample: select columns, compute new values (use .()), or add/update columns with :=.\n\n\nUse by for anything related to grouped operations.\n\nExample: calculate summaries by group.\n\n\n\n\nWith just these three pieces (i, j, and by), you can handle most data manipulation tasks in data.table."
  },
  {
    "objectID": "Lec2.html#section-2",
    "href": "Lec2.html#section-2",
    "title": "Day 2: Data wrangling with data.table",
    "section": "",
    "text": "Next, we will see a few advanced topics:\n\nReshaping Data\nMerging Multiple Datasets\n(and the %&gt;% operator if we have time)."
  },
  {
    "objectID": "Lec2.html#reshape-data",
    "href": "Lec2.html#reshape-data",
    "title": "Day 2: Data wrangling with data.table",
    "section": "6. Reshape Data",
    "text": "6. Reshape Data\n\n\nBasics\nLong to wide\nWide to long\nWhy reshape data?\nIn-class exercise\n\n\n\nData often comes in two formats: long or wide.\nExample:\n\n\nLong data:\nEach student appears in multiple rows (one per year).\n\n\n   student  year  math reading\n    &lt;char&gt; &lt;num&gt; &lt;num&gt;   &lt;num&gt;\n1:   Alice  2021    78      82\n2:   Alice  2022    85      88\n3:     Bob  2021    92      90\n4:     Bob  2022    95      93\n5: Charlie  2021    88      85\n6: Charlie  2022    90      87\n7:   Diana  2021    70      75\n8:   Diana  2022    80      83\n\n\n\nWide data\nEach student appears in one row, with columns for each year’s scores.\n\n\n   student math_2021 math_2022 reading_2021 reading_2022\n    &lt;char&gt;     &lt;num&gt;     &lt;num&gt;        &lt;num&gt;        &lt;num&gt;\n1:   Alice        78        85           82           88\n2:     Bob        92        95           90           93\n3: Charlie        88        90           85           87\n4:   Diana        70        80           75           83\n\n\n\n\n\nWe can convert one format to another using dcast() and melt() functions of data.table package.\n\n\n\n\nUse dcast() function converts long form to wide form\n\nBasic Syntax:\n\ndcast(data, LHS ~ RHS , value.var = c(\"var1\", \"var2\"))\n\n\n\nLHS: set of id variables (variables (columns) that you don’t want change).\n\nRHS: set of variables to be used as the column index.\n\nvalue.var: set of variables whose values will be filled to cast.\n\n\nExample:\nSuppose that we want to organize the data so that each student’s math and reading scores appear in the same row.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nTips\n\nBefore coding a reshape, first visualize the format you want the data to take.\nI often sketch a small example table.\n\nThis helps me to understand what variables I need to use as LHS, RHS, and value.var.\n\n\n\n\n\n\nUse melt() function to convert wide form to long form\n\nBasic Syntax:\n\nmelt(data, id.var = c(\"id_var1\", \"id_var2\"), measure.vars = c(\"var1\", \"var2\"))\n\n\n\nid.vars: the set of id variables (variables (columns) that you don’t want change).\n\nmeasure.vars: the set of columns you want to collapse (or combine) together.\n\nvalue.name: (optional) the name of the new column that will store the values of the variables in measure.vars, the default is value\n\n\n\nExample:\nLet’s get back to the original data format student_long from student_wide.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nNotice that the year info is stored as variable (1, 2).\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nSummarizing is easier in long form.\n\nExample: average math/reading score by year.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nVisualization is easier in long form.\n\nExample: plotting scores by year (when we use ggplot later).\n\n\n\n\n\nQuestions\nAnswers\n\n\n\nUsing the following long-form data named long_data, can you get back student_long?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec2.html#merge-multiple-datasets",
    "href": "Lec2.html#merge-multiple-datasets",
    "title": "Day 2: Data wrangling with data.table",
    "section": "7. Merge Multiple Datasets",
    "text": "7. Merge Multiple Datasets\n\n\nBasics\nExample\nIn-class exercise1\nIn-class exercise 2\n\n\n\nYou can use the merge() function from the data.table package to merge two datasets. \nBasic Syntax:\n\n# Merge data y to data x keeping all rows from data x\nmerge(x, y, by = \"key_column\", all.x = TRUE)\n\n\n\nx, y: data tables.\n\nby: specifies variables that let you merge two datasets.\n\nall.x = TRUE means that all rows from x are maintained in the merged dataset, and only matching rows from y are included.\n\n\nNote: The order of the datasets matter.\n\n\n\n\nInstructions\nMerge\n\n\n\nLet’s play around with the merge() function using the following small data.\n\n\nData 1\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nData2\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nNote that the students included inmath_data and reading_data are slightly different. This is to show how the merge() function works when there are unmatched rows in the two datasets.\n\nTo merge these two datasets, student works because it is the key column. \n\n\n\n\n(1) Merge reading_data to math_data, keeping all rows from math_data.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n(2) Merge math_data to reading_data, keeping all rows from reading_data.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n(3) If you want to keep all rows from both datasets, set all = TRUE.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\nQuestions\nAnswers\n\n\n\n\nIn the flights data, the carrier column contains two-letter codes for airlines. Let’s translate these codes into the full name of the airline.\n\nAirline data from nycflights13 package contains the full name of the airline corresponding to the two-letter code. The following code loads the airline data.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nMerge flights and airlines data, keeping all rows from the flights data. Which variable should be used as a key column?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nObviously, flights data is the main data, so we should keep all rows from the flights data.\nThe key column should be carrier because it is the common variable in both datasets, and it gives one-to-one correspondence between the two datasets.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\nQuestions\nAnswers\n\n\n\nRun the following code to create two datasets: math_data and reading_data.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nMerge these two datasets, keeping all rows from math_data. Which variable(s) should be used as key columns?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nHere you should use both student and year as key columns.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec2.html#motivation",
    "href": "Lec2.html#motivation",
    "title": "Day 2: Data wrangling with data.table",
    "section": "Motivation",
    "text": "Motivation\n\nIn R, you need to assign the result of each operation to a new object if you want to use the result in the subsequent process.\nBut sometimes, some objects are just intermediate results that you don’t need to keep.\n\nExample\nLet’s first create flights_mini data from flights data of nycflights13 package in the data.table format.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe first three lines yield intermediate results to make the final flight_mini, and you don’t need to keep those.\n\nYou can create flights_mini without using those intermediate steps with the chaining operation in data.table package, but it’s hard to read!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec2.html#introduction",
    "href": "Lec2.html#introduction",
    "title": "Day 2: Data wrangling with data.table",
    "section": "Introduction",
    "text": "Introduction\n\n\nWhat is %&gt;%?\nBasics\nRefer to the Preceding Object\n\n\n\n\n\n%&gt;% a special symbol in R, called a pipe operator. It comes from the magrittr package.\nIt’s a powerful tool to write linear sequence of operations in a more readable way.\n\n\nNote: When you load the dplyr package, magrittr package is automatically loaded as well. So, you don’t need to load the magrittr package separately to use %&gt;%.\n\n\n%&gt;% takes the output of the code on its left and feeds it as the first argument to the function on its right.\n\nExample 1\nfun1(input1) \nis the same as\ninput1 %&gt;% fun1()\n\nExample 2\noutput1 &lt;- fun1(input1)\noutput2 &lt;- fun2(output1)\nis the same as\noutput2 &lt;- fun1(input1) %&gt;% fun2()\n\n\nWhat if you want to use the object defined before %&gt;% as the second or third argument of the subsequent function?\nYou can refer the preceding object by . in the subsequent function.\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nTip - Whenever you use %&gt;%, I recommend you always use . in the subsequent function to explicitly denote the destination of the object defined before %&gt;% even if it is the first argument."
  },
  {
    "objectID": "Lec2.html#example-2",
    "href": "Lec2.html#example-2",
    "title": "Day 2: Data wrangling with data.table",
    "section": "Example",
    "text": "Example\nWithout %&gt;%\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWith %&gt;%\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nNote that the order of execution is the same as the order in which the functions are written."
  },
  {
    "objectID": "Lec2.html#summary-1",
    "href": "Lec2.html#summary-1",
    "title": "Day 2: Data wrangling with data.table",
    "section": "Summary",
    "text": "Summary\n The topics in the second part of this lecture were more advanced, so you don’t need to memorize every function right away.\nWhat I want you to remember are the following key ideas:\n\nYou can reshape data using the functions dcast() and melt(). Depending on your goal, one format (wide or long) may be easier to analyze than the other.\nYou can merge datasets using the merge() function, but you must have at least one common key column between the datasets.\n\nYou don’t need to use %&gt;% operator, unless you thinks it would be more convenient."
  },
  {
    "objectID": "Lec2.html#exercise-1",
    "href": "Lec2.html#exercise-1",
    "title": "Day 2: Data wrangling with data.table",
    "section": "Exercise 1",
    "text": "Exercise 1\n\n\nInstructions\nAnswers\n\n\n\n\nFind the flight company with the longest departure delay. (Hint: use max() function to find the maximum value of dep_delay column)\nSubset the information of flights that headed to MSP (Minneapolis-St Paul International Airport) in February. Let’s name it “msp_feb_flights”. How many flights are there?\nCalculate the median, interquartile range (\\(IQR = Q3 − Q1\\)) for arr_delays of flights in in the msp_feb_flights dataset and the number of flights, grouped by carrier. Which carrier has the most variable arrival delays?\n\n\nHints: IQR = Q3 − Q1 (the difference between the 75th percentile and the 25th percentile.) Use quantile() function to calculate the quantiles.\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec2.html#exercise-2",
    "href": "Lec2.html#exercise-2",
    "title": "Day 2: Data wrangling with data.table",
    "section": "Exercise 2",
    "text": "Exercise 2\n\n\nInstructions\nAnswers\n\n\n\nIf you were selecting an airport simply based on on-time departure percentage, which NYC airport would you choose to fly out of? - To address this question, first, define a new variable which indicates on-time departure. On-time-departure can be defined as a departure delay of less than or equal to 0. Then, calculate the on-time departure rate for each airport.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec2.html#exercise-3",
    "href": "Lec2.html#exercise-3",
    "title": "Day 2: Data wrangling with data.table",
    "section": "Exercise 3",
    "text": "Exercise 3\n\n\nData\nInstructions\nSolutions\n\n\n\nFor this exercise problem, we will use journal data from the AER package.\n- First, load the data and convert it to data.table object using setDT function (or. as.data.table()). Take a look at the data.\n- Also, type ?journal to see the description of the data.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nCalculate the average number of pages and price for the entire dataset.\nShow the title, citations, price, and subs columns for the top 5 journals (title) with the highest number of citations (citations). (Hint: use order() function to sort the data by citations in descending order.).\nThis dataset is created in the year 2000. Calculate the age (age) of each journal by subtracting the start year (foundingyear) of the journal from 2000. Select the columns, price, subs, citations, and pages, and age. Use that data to create a correlation matrix between those variables using the cor() function. (Hint: use this syntax: cor(data)). Can you find anything interesting from the correlation matrix?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec2.html#useful-functions",
    "href": "Lec2.html#useful-functions",
    "title": "Day 2: Data wrangling with data.table",
    "section": "Useful functions",
    "text": "Useful functions\n\n.N\ncopy()\nsetnames()\norder()\nshift()\n\nduplicated(): find duplicates\n\nunique(): find unique observations\nfcase()"
  },
  {
    "objectID": "Lec2.html#fcase",
    "href": "Lec2.html#fcase",
    "title": "Day 2: Data wrangling with data.table",
    "section": "fcase()",
    "text": "fcase()\n\nfcase() function is useful when you want to define a variable that takes different values based on conditions.\nfcase() function returns the first value for which the corresponding condition is TRUE. If no condition is TRUE, it returns the default value.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nExample: Define seasons (Winter: Dec-Feb, Spring: Mar-May, Summer: Jun-Aug, Fall: Sep-Nov)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#section",
    "href": "Lec1.html#section",
    "title": "Day 1: Basics of R",
    "section": "",
    "text": "Slide Guide\n\nClick on the three horizontally stacked lines at the bottom left corner of the slide, then you will see the table of contents, and you can jump to the section you want to see.\nHitting letter “o” on your keyboard and you will have a panel view of all the slides.\nYou can directly write and run R code, and see the output on slides.\nWhen you want to execute (run) code, hit command + enter (Mac) or Control + enter (Windows) on your keyboard. Alternatively, you can click the “Run Code” button on the top left corner of the code chunk.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#section-1",
    "href": "Lec1.html#section-1",
    "title": "Day 1: Basics of R",
    "section": "",
    "text": "Learning Objectives\n\nTo understand the R coding rules.\nTo understand the basic types of data and structure in R, and to be able to manipulate them.\nTo be able to use base R functions to do some mathematical calculations.\nTo be able to create R projects and save and load data in R.\n\n\n\n Reference\n\nSection 6: Workflow: scripts, R for Data Science\nSection 8: Workflow: projects, R for Data Science"
  },
  {
    "objectID": "Lec1.html#section-2",
    "href": "Lec1.html#section-2",
    "title": "Day 1: Basics of R",
    "section": "",
    "text": "Today’s outline\n\nGeneral coding rules in R\nBasic data types in R\n\nTypes of Data Structures in R\n\nVector (one-dimensional array)\nMatrix (Two-dimensional array)\nData Frame\nList\n\n\nMatrix/Linear Algebra in R\nLoading and Saving Data\nExercise problems\nAppendix: Useful base-R functions"
  },
  {
    "objectID": "Lec1.html#before-you-start",
    "href": "Lec1.html#before-you-start",
    "title": "Day 1: Basics of R",
    "section": "Before you start",
    "text": "Before you start\n\n\nWe’ll cover many basic topics today.\nYou don’t need to memorize nor completely understand all the contents in this lecture.\nAt the end of each section, I will include a summary of the key points you need to know. As long as you understand those key points, you are good to go."
  },
  {
    "objectID": "Lec1.html#general-coding-rules-in-r",
    "href": "Lec1.html#general-coding-rules-in-r",
    "title": "Day 1: Basics of R",
    "section": "General coding rules in R",
    "text": "General coding rules in R\n\n\nBasics\nObject Naming\nPackages\n\n\n\n\nR is object-oriented: Everything in R is an “object” that you can name and reuse.\n\nCreating objects: Use &lt;- or = to store information in objects.\n\nExample: e.g., x &lt;- 1 assigns 1 to an object called x.\n\n\n\nObjects can be overwritten: If you use the same name twice, the new value replaces the old one.\nView your objects: Simply type the object name to see what’s stored inside. \n\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nObject names must start with a letter (not a number or symbol).\n\n\nUse underscores _ or dots . to separate words in names.\n\n\nChoose descriptive names that tell you what the object contains.\n\nGood: student_age, exam_scores\n\nAvoid: x, data1, thing\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nPackages provide extra functions beyond base R\n\n\nInstall once: install.packages(\"package_name\")\n\n\nLoad every session: library(package_name)\n\n\nTroubleshooting: See could not find function \"xxxx\"? → Load the package!"
  },
  {
    "objectID": "Lec1.html#overview",
    "href": "Lec1.html#overview",
    "title": "Day 1: Basics of R",
    "section": "Overview",
    "text": "Overview\n\n\nData types in R\nHow to check data types?\nData Type Conversion\n\n\n\nThese are the basic data elements in R.\n\n\n\n\n\n\n\nData Type\nDescription\nExample\n\n\n\nnumeric\nGeneral number, can be integer or decimal.\n\n5.2, 3L (the L makes it integer)\n\n\ncharacter\nText or string data.\n\"Hello, R!\"\n\n\nlogical\nBoolean values.\n\nTRUE, FALSE\n\n\n\ninteger\nWhole numbers.\n\n2L, 100L\n\n\n\ncomplex\nNumbers with real and imaginary parts.\n3 + 2i\n\n\nraw\nRaw bytes.\ncharToRaw(\"Hello\")\n\n\nfactor\nCategorical data. Can have ordered and unordered categories.\nfactor(c(\"low\", \"high\", \"medium\"))\n\n\n\n\n\n\nThree main data types you’ll use most often: numeric, character, and logical.\n\n\nText must be in quotes:\n\nCorrect: \"Hello\" or 'Hello'\n\nWrong: Hello (without quotes)\n\n\n\n\n\nUse class() or is.XXX() to examine the data types.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nConvert between data types using as.XXX() functions:\n\n\nas.numeric() → converts to numbers\n\n\nas.character() → converts to text\n\n\nas.factor() → converts to categories\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#logical-values-a.k.a.-boolean-values",
    "href": "Lec1.html#logical-values-a.k.a.-boolean-values",
    "title": "Day 1: Basics of R",
    "section": "Logical values (a.k.a. Boolean values)",
    "text": "Logical values (a.k.a. Boolean values)\n\n\nBasics\nExample\n\n\n\n\nLogical values are TRUE, FALSE, and NA (not available/undefined).\nThey are often generated by comparison operators: &lt;, &gt;, &lt;=, &gt;=, ==, !=.\nLogical operators include & (and), | (or), and ! (not). \nEvery comparison evaluates to TRUE, FALSE, or NA.\nWhen treated as numbers, TRUE equals 1 and FALSE equals 0.\nLogical values can be used as indices to subset vectors or data.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#summary",
    "href": "Lec1.html#summary",
    "title": "Day 1: Basics of R",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\nKey points\n\n\n\nR defines several basic data types, including numeric, character, and logical.\nUse the class() function to check the data type of an object.\nUse as.XXX() functions to convert an object from one type to another.\nLogical values play an important role in many R operations."
  },
  {
    "objectID": "Lec1.html#types-of-data-structures-in-r",
    "href": "Lec1.html#types-of-data-structures-in-r",
    "title": "Day 1: Basics of R",
    "section": "Types of Data Structures in R",
    "text": "Types of Data Structures in R\nR provides several types of data structures for storing data.\n\n\n\n\n\n\n\n\n\nData Structure\nDescription\nCreation Function\nExample\n\n\n\nVector\nOne-dimensional; Holds elements of the same type.\nc()\nc(1, 2, 3, 4)\n\n\nMatrix\nTwo-dimensional; Holds elements of the same type.\nmatrix()\nmatrix(1:4, ncol=2)\n\n\nArray\nMulti-dimensional; Holds elements of the same type.\narray()\narray(c(1:12), dim = c(2, 3, 2))\n\n\nList\nCan hold elements of different types.\nlist()\nlist(name=\"John\", age=30, scores=c(85, 90, 92))\n\n\nData Frame\nLike a table; Each column can hold different data types. This is the most common data structure.\ndata.frame()\ndata.frame(name=c(\"John\", \"Jane\"), age=c(30, 25))"
  },
  {
    "objectID": "Lec1.html#vec",
    "href": "Lec1.html#vec",
    "title": "Day 1: Basics of R",
    "section": "Vector (one-dimensional array)",
    "text": "Vector (one-dimensional array)\n\n\nBasics\nExample\n\n\n\n\nA vector object is a collection of elements of the same type.\n\nVectors can contain numbers, characters, or logical values.\n\nUse c() to create a vector or to combine vectors (c stands for combine).\n\n\nBasic syntax\nc(element1, element2, element3, ...)\n\nYou can name each element in a vector:\nc(x1 = element1, x2 = element2, x3 = element3, ...)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#vector-how-to-manipulate",
    "href": "Lec1.html#vector-how-to-manipulate",
    "title": "Day 1: Basics of R",
    "section": "Vector: How to manipulate?",
    "text": "Vector: How to manipulate?\n\n\nIndexing\nLogical Vectors\n\n\n\nBasics\n\nUse square brackets [] to extract one or more elements from a vector by their position.\nIf a vector has names, you can extract elements using their names.\nTo update an element, assign a new value to the position (or name) you want to change. \n\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nA logical vector contains only logical values (TRUE and FALSE).\n\nLogical vectors can be used as index vectors: only elements matching TRUE are returned.\n\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#in-class-exercise",
    "href": "Lec1.html#in-class-exercise",
    "title": "Day 1: Basics of R",
    "section": "In-class Exercise",
    "text": "In-class Exercise\nThe following code randomly samples 30 numbers from a uniform distribution between 0 and 1, and stores the result in x.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nQuestions \n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#mat",
    "href": "Lec1.html#mat",
    "title": "Day 1: Basics of R",
    "section": "Matrix (Two-dimensional array)",
    "text": "Matrix (Two-dimensional array)\n\n\nBasics\nExample 1\nExample 2\n\n\n\n\nA matrix is a collection of elements of the same type arranged in rows and columns (essentially a vector with an added dimension attribute).\nIn practice, matrices are less common for real-world data storage and are used mainly for linear algebra operations.\nUse the matrix() function to create a matrix.\n\n\nSyntax\nmatrix(data = vector_data, nrow = number_of_rows, ncol = number_of_column, byrow = FALSE)\n\n\nYou need to specify the vector_data and the number_of_rows and number_of_columns.\nIf the length of vector_data is a multiple of number_of_columns (or number_of_rows), R fills in the other dimension automatically.\nBy default, values are filled by column. Use byrow = TRUE to fill by row.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nYou can also create a matrix by combining multiple vectors using cbind() or rbind() functions.\n\nrbind() function combines vectors by row.\ncbind() function combines vectors by column.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#matrix-how-to-manipulate",
    "href": "Lec1.html#matrix-how-to-manipulate",
    "title": "Day 1: Basics of R",
    "section": "Matrix: How to manipulate",
    "text": "Matrix: How to manipulate\n\n\nIndexing\nMiscellaneous\n\n\n\n\nYou can access matrix elements with [].\nSpecify the row index and column index: [row, col].\nLeave one index blank to select an entire row or column.\n\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nYou can add column names and row names to a matrix using colnames() and rownames() functions. If a matrix has column names and row names, you can use the names as the index.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#matrix-exercise-problem-optional",
    "href": "Lec1.html#matrix-exercise-problem-optional",
    "title": "Day 1: Basics of R",
    "section": "Matrix: Exercise Problem (Optional)",
    "text": "Matrix: Exercise Problem (Optional)\nUse the following matrix:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nQuestions \n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#df",
    "href": "Lec1.html#df",
    "title": "Day 1: Basics of R",
    "section": "Data Frame",
    "text": "Data Frame\n\n\nBasics\nIndexing\n$ and [[ ]] operator\nAdding and Removing Columns\nMiscellaneous\n\n\n\n\nA data.frame class object is similar to a matrix, but each column can store a different data type.\nIt is designed for tabular data, which makes it the most common structure in real-world datasets.\n\nSyntax\ndata.frame(column_1 = vector_1, column_2 = vector_2)\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nIf you do not provide column names, R automatically assigns default names (e.g., X1, X2, X3).\n\n\n\n\nYou can access elements of a data.frame using square brackets [].\nSpecify the row and column index, similar to a matrix.\n\nIndexing options include:\n\n\nPositional index (e.g., df[1, 2])\n\n\nColumn names (e.g., df[ , \"Age\"])\n\n\nLogical vectors (e.g., df[df$Age &gt; 20, ])\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nYou can extract a single column from a data.frame using the $ or [[ ]] operator.\n$ and [[ ]] can only return one column at a time as a vector, while [] can select multiple columns.\nType ?\"$\", ?\"[\", and ?\"[[\" in the Console for details.\nInside [[ ]], provide the column name as a character (e.g., df[[\"Age\"]]).\nWhy this matters: many R functions (mean(), sum(), sqrt(), etc.) work on vectors, and $ / [[ ]] are the fastest way to extract a vector for calculations.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nYou can add a new column to a data.frame object using the $ operator.\nSyntax\ndata_frame$new_column &lt;- vector_data\n\nA new column added to a data.frame must have the same length as the number of rows.\nIf the length does not match, R will recycle the values to fill the column.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#in-class-exercise-1",
    "href": "Lec1.html#in-class-exercise-1",
    "title": "Day 1: Basics of R",
    "section": "In-class Exercise",
    "text": "In-class Exercise\nWe will use the built-in dataset mtcars for this exercise. Run the following code to load the data.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nQuestions\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#with-and-within",
    "href": "Lec1.html#with-and-within",
    "title": "Day 1: Basics of R",
    "section": "with() and within()",
    "text": "with() and within()\n\nThe with() function evaluates an expression inside a data frame.\n\nExample: with(df_student, mean(Age)) instead of mean(df_student$Age)\n\n\n\nThe within() function is similar, but it allows you to modify the data frame directly.\n\nExample: df_student &lt;- within(df_student, { GPA2 &lt;- GPA^2 })\n\n\n\nUsing these functions helps avoid repeatedly typing the data frame name and $.\n\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#list",
    "href": "Lec1.html#list",
    "title": "Day 1: Basics of R",
    "section": "List",
    "text": "List\n\n\nBasics\nIndexing\n\n\n\n\nA list in R can store elements of different types and sizes: numbers, characters, vectors, matrices, data frames, or even other lists.\nA list is a flexible container that can hold any combination of data structures.\nUse the list() function to create a list.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nYou can access list elements using $, [], or [[ ]].\n[] returns a list containing the selected elements.\n[[ ]] returns a single element itself (not wrapped in a list).\n$ is shorthand for [[ ]], but it only works if the list elements are named.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#summary-1",
    "href": "Lec1.html#summary-1",
    "title": "Day 1: Basics of R",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\nKey points\n\n\n\nKnow how to create the main data structures in R: vector, matrix, data.frame, and list.\n\nVectors and matrices store one data type.\n\nData frames and lists can store different data types.\n\n\n\nLearn how to access, subset, and modify elements using indexing.\n\nIndexing can be positional, logical, or by name.\n\nOperators include [], $, and [[ ]]."
  },
  {
    "objectID": "Lec1.html#r-base-functions-for-data-import-and-export",
    "href": "Lec1.html#r-base-functions-for-data-import-and-export",
    "title": "Day 1: Basics of R",
    "section": "R base functions for data import and export",
    "text": "R base functions for data import and export\n\nLike other softwares (e.g., Stata, Excel) do, R has two native data formats: .Rdata (or .rdata) and .Rds (or .rds).\n\n\n.Rdata is used to save multiple R objects.\n\n.Rds is used to save a single R object.\n\n\n\n\n\n\n.Rdata format\n\nLoad data:\n\nload(\"path_to_Rdata_file\")\n\nSave data:\n\nsave(object_name1, object_name2, file = \"path_to_Rdata_file\")\n\n.Rds format\n\nLoad data:\n\nreadRDS(\"path_to_Rds_file\")\n\nSave data:\n\nsaveRDS(object_name, file = \"path_to_Rds_file\")"
  },
  {
    "objectID": "Lec1.html#setting-the-working-directory",
    "href": "Lec1.html#setting-the-working-directory",
    "title": "Day 1: Basics of R",
    "section": "Setting the working directory",
    "text": "Setting the working directory\n\n\nBasics\nWorking Directory\nsetwd()\nR project\n\n\n\nTo access to the data file, you need to provide the path to the file (the location of the data file).\n\nExample\nSuppose that I want to load data_example.rds in the Data folder. On my computer, the full path (i.e., absolute path) to the file is /Users/qingyin/Dropbox/Teaching/R_Review_2025/Data/data_example.rds.\n\n# this code only works in my local machine\ndf_example &lt;- readRDS(file = \"/Users/qingyin/Dropbox/Teaching/R_Review_2025/Data/data_example.rds\")\n\n\nWhy avoid hard-coding full paths?\n\nTyping the full file path every time is cumbersome and slows you down.\n\nHard-coded paths make your code less portable:\n\nTeam members may have different folder structures.\n\nCode that works on your computer might fail on theirs.\n\n\n\n\n\n\nThe working directory is the folder where R looks for files to load and saves files you create.\n\nCheck the current working directory with getwd().\n\nBy default, R uses your home directory (or the project folder if you’re in an R Project).\n\n\n\n\nIf you often import or save data in a specific folder, it helps to set that folder as the working directory.\nUse setwd() to change the working directory:\n\nExample\nIn my case, I set the working directory to the R_Review_2025 folder.\n\nsetwd(\"/Users/qingyin/Dropbox/Teaching/R_Review_2025\")\n\nNow, R will look for the data file in the R_Review_2025 folder by default. So, I can load the data using relative path, not absolute path.\n\ndf_example &lt;- readRDS(file = \"Data/data_example.rds\")\n\n\nProblems\n\n\nsetwd() still relies on an absolute path, which can vary across people.\n\ne.g., one person saves files in Dropbox, another in Google Drive).\n\n\nThis means setwd() does not fully solve the collaboration problem.\n\ncode may still break if teammates have different folder structures.\n\n\n\n\n\n\n\nWhat is it?\nLet’s create a project!\nLoad the data\n\n\n\n\n“R experts keep all the files associated with a project together — input data, R scripts, analytical results, figures. This is such a wise and common practice that RStudio has built-in support for this via projects.” - R for Data Science Ch 8.4\n\n\nRStudio Projects\n\nAn RStudio project is a way to organize your work.\nWhen you open a Project, R automatically sets the working directory to the folder containing the .Rproj file — no need for setwd().\nAs long as the folder structure inside the Project is consistent, you can share code with teammates and relative paths will work for everyone.\n\n\n\nFollow this steps illustrated in this document: R for Data Science Ch 8.4\n\n\n\nIn RStudio, check the top-right corner of the window to see the active Project name.\nAlternatively, open a Project by double-clicking the .Rproj file in Finder (Mac) or File Explorer (Windows).\nUse getwd() to confirm the current working directory — it should be the Project folder.\nLoad the data_example.rds data file with readRDS()."
  },
  {
    "objectID": "Lec1.html#loading-data-other-than-.rds-.rds-format",
    "href": "Lec1.html#loading-data-other-than-.rds-.rds-format",
    "title": "Day 1: Basics of R",
    "section": "Loading data other than .Rds (.rds) format",
    "text": "Loading data other than .Rds (.rds) format\n\n\nBasics\nLet’s do it\n\n\n\n\nR can load data from various formats including .csv, .xls(x), and.dta.\nThere exists many functions that can help you to load data:\n\n\nread.csv() to read a .csv file.\n\n\nread_excel() from the readxl package to read data sheets from an .xls(x) file.\n\n\nread.dta13() function from the readstata13 package to read a STATA data file (.dta).\n\n\n\n\nUse import() function of the rio package\n\n\nBut import() function from the rio package might be the most convenient one to load various format of data.\n\nUnlike, read.csv() and read.dta13() which specialize in reading a specific type of file, import() can load data from various sources.\n\n\n\n\n\nIn Data folder, data_example data is saved with three different formats: data_example.csv, data_example.dta, and data_example.xlsx. Let’s load the data using import() function on your Rstudio.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#saving-the-data",
    "href": "Lec1.html#saving-the-data",
    "title": "Day 1: Basics of R",
    "section": "Saving the data",
    "text": "Saving the data\n\nYou can save data in many formats (.csv, .dta, .xlsx, etc.).\n\n\nBut unless you need compatibility with other software, it’s best to save data in .rds.\n\nHow: saveRDS(object_name, path_to_save)\n\n\n\n\n\nWhy prefer .rds?\n\nDesigned for R — no reason to use another format if you work only in R.\n\n\nFaster and more efficient for saving and loading.\n\nProduces smaller file sizes compared to .csv or .xlsx when data gets larger.\n\n(Try it! Check the size of the data_example dataset saved in different formats.)\n\n\nLet’s try!\n\nLoad the data_example data in the Data folder.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#summary-2",
    "href": "Lec1.html#summary-2",
    "title": "Day 1: Basics of R",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\nKey points\n\n\n\nRstudio project (.Rproj) is a useful tool to organize your work. As long as the folder structure under the .Rproj is the same, you can share the code involving data loading with your team members.\n\nTo load data:\n\nuse readRDS() function for .Rds (.rds) format.\n\nyou can use import() function from the rio package for various format.\n\n\n\nTo save the data, it is recommended to use .rds format and use saveRDS() function."
  },
  {
    "objectID": "Lec1.html#exercise-problems-1-vector",
    "href": "Lec1.html#exercise-problems-1-vector",
    "title": "Day 1: Basics of R",
    "section": "Exercise Problems 1: Vector",
    "text": "Exercise Problems 1: Vector\n\n\nProblems\nAnswers\n\n\n\n\nCreate a sequence of numbers from 20 to 50 and name it x. Let’s change the numbers that are multiples of 3 to 0.\nsample() is commonly used in Monte Carlo simulation in econometrics. Run the following code to create r. What does it do? Use ?sample to find out what the function does.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nFind the value of mean and SD of vector r without using mean() and sd().\nFigure out which position contains the maximum value of vector r. (use which() function. Run ?which() to find out what the function does.).\nExtract the values of r that are larger than 50.\nExtract the values of r that are larger than 40 and smaller than 60.\nExtract the values of r that are smaller than 20 or larger than 70.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#exercise-problem-2-data-frame",
    "href": "Lec1.html#exercise-problem-2-data-frame",
    "title": "Day 1: Basics of R",
    "section": "Exercise Problem 2: Data Frame",
    "text": "Exercise Problem 2: Data Frame\n\n\nProblems\nAnswer\n\n\n\n\n\nLoad the file nscg17tiny.dta. You can find the data in the Data folder.\n\nThis data is a subset of the National Survey of College Graduates (NSCG) 2017, which collects data on the educational and occupational characteristics of college graduates in the United States.\n\n\nEach row corresponds to a unique respondent. Let’s create a new column called “ID”. There are various ways to create an ID column. Here, let’s create an ID column that starts from 1 and increments by 1 for each row.\nTo take a quick look at the summary statistics of a specific column, summary() function is useful. Use summary() to create a table of the descriptive statistics for hrswk. You’ll provide hrswk column to summary() as a vector.\nCreate a new variable in your data that represents the z-score of the hours worked (use hrswk variable).\\(Z = (x - \\mu)/\\sigma\\), where \\(Z = \\text{standard score}\\), \\(x =\\text{observed value}\\), \\(\\mu = \\text{mean of sample}\\), and \\(\\sigma = \\text{standard deviation of the sample}\\).\nCalculate the share of observations in your data sample with above average hours worked.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec1.html#useful-functions",
    "href": "Lec1.html#useful-functions",
    "title": "Day 1: Basics of R",
    "section": "Appendix: A List of Useful R Built-in Functions",
    "text": "Appendix: A List of Useful R Built-in Functions\n\n\nFor data manipulation\nFor numerical manipulation\n\n\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\nlength()\nget the length of the vector and list object\n\n\n\nnrow(),ncol()\n\nget the number of rows or columns\n\n\ndim()\nget the dimension of the data\n\n\n\nrbind(),cbind()\n\nCombine R Objects by rows or columns\n\n\n\ncolMeans(), rowMeans()\n\ncalculate the mean of each column or row\n\n\n\nwith and within()\n\nYou don’t need to use `—\n\n\n\n\n\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\nsum(), mean(), var(), sd(), cov(), cor(), max(), min(), abs(), round()\n\n\n\n\nlog() and exp()\n\nLogarithms and Exponentials\n\n\nsqrt()\nComputes the square root of the specified float value.\n\n\nseq()\nGenerate a sequence of numbers\n\n\nsample()\nrandomly sample from a vector\n\n\nrnorm()\ngenerate random numbers from normal distribution\n\n\nrunif()\ngenerate random numbers from uniform distribution"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Qingyin Cai",
    "section": "",
    "text": "Drought and Fresh Produce Production in California (with Metin Çakır and Timothy Beatty)  R & R at Agricultural Economics\n\nAbstract: California’s increasingly frequent and intense drought is a pressing problem for the state’s agriculture and the U.S. food supply, as the state is the major producer of many agricultural products. Particularly, California supplies more than half of all fruit and vegetables in the country. This paper examines the severity of the problem by estimating the impacts of the drought on California’s fresh fruit and vegetable production. We estimate panel data models using comprehensive, county-level agriculture, irrigation, and weather data from 2000 to 2019. Our findings indicate that droughts significantly reduce total output, ranging from 1.2% to 2.2% for each additional week of drought. The estimated effect is driven by lower yields and fewer harvested acres due to the drought. The drought effects also differ among crops, with thirsty crops and crops with lower economic returns and established insurance programs being disproportionately affected. Results also show the extent to which higher irrigation levels mitigate the adverse effects of drought. Our findings provide insights into the importance of enhancing drought-related risk management and implications for designing cost-effective policies for future adaptation decisions.\n\n\n\nDrought and Farm Consolidation: Long-Run Evidence from U.S. Agriculture (with Metin Çakır)\n\nAbstract: In this study, we examine the long-run impacts of drought on farm consolidation in the U.S. crop sector from 1982-2022. Using four decades of county-level data and a long-difference design, we find that cumulative drought exposure significantly increases farm size, primarily through the exit of smaller farms. Effects are strongest in rainfed regions and among field crops, while specialty crop areas show weaker or negative responses to drought. These findings highlight drought as a structural force in U.S. agriculture and underscore the need for targeted climate adaptation policies.\n\n\n\nCalifornia Drought, Fresh Fruit and Vegetable Prices, and Consumer Welfare (with Metin Çakır, Timothy Beatty, and Timothy Park)\n\nAbstract: California produces more than a third of all vegetables and two-thirds of all fruits and nuts in the United States and is the largest producer of over fifty fruits, vegetables, and tree nuts. Meanwhile, California agriculture faces important challenges due to sustained drought with increasing frequency and severity across the state since 2011. This article estimates the effect of the recent California drought on the retail prices of fresh fruits and vegetables (FFV) using panel data models. We build a dataset comprising detailed information on FFV prices and the drought. Specifically, we construct a monthly panel price index for fresh fruits and vegetables using retail scanner data and obtain California’s county-level historical drought data from the United States Drought Monitor. In our estimation, we account for the heterogeneous effects of the drought across products and space. Our main finding is that the drought had a positive and significant effect on FFV prices. This effect is generally larger on fruits than vegetables and is robust to alternative measures of drought and model specifications. Furthermore, we find that the drought’s impacts on production and imports are among the significant determinants of its overall effect on prices.\n\n\n\nDoes the Recent Food Price Inflation Differ by Store Format? (with Metin Çakır and Megan Sweitzer)\n\nAbstract: Recent spikes in food prices have raised significant economic concerns in the United States. Understanding how food price inflation varies across store formats provides valuable insights into consumer behavior and the strategies retailers employ during economic downturns. In this study, we use retail scanner data to construct price indices by store format for various food product groups, allowing us to estimate differences in the rates of price changes across stores. We then estimate a structural store-choice model to examine how these differential rates of price changes affect consumers’ preferences for different store formats. Our findings reveal that food price inflation rates vary significantly by store format, with nontraditional stores generally experiencing lower inflation rates than traditional stores across most food categories. These differential price changes also influence consumer store and product choices.\n\n\n\nEmotional Shocks and Consumer Spending (with Qingxiao Li)  R & R at Journal of Economic Behavior & Organization\n\nAbstract: This study examines how emotional shocks affect consumer spending by using unexpected National Football League (NFL) game outcomes as a natural experiment. We analyze consumer scanner data from 83,332 households during regular seasons from 2004 to 2019, using Las Vegas pregame point spreads and actual outcomes to identify emotional shocks. We find that unexpected losses by home teams increase household shopping trips and spending, while unexpected wins reduce spending. These emotional impacts are concentrated within three days post-game and amplified for high-stakes games. These findings provide insights into how emotional shocks from unexpected events can influence consumer spending behavior.\n\n\n\nBad Air Days: Pollution, Forecasts, and Consumer Shopping Behavior (with Qingxiao Li and Lifeng Ren)\n\nAbstract: This paper provides nationwide evidence of how short-term exposure to fine particulate matter causally affects household retail shopping behavior in the United States. Linking detailed household transaction records with daily air quality data, we employ an instrumental-variable strategy that exploits exogenous, wind-driven variation in pollution. We find that air pollution reduces both store visits and retail spending. Consumers disproportionately reduce purchases of nonessential goods and partially shift toward online shopping. Higher-income and younger households show greater avoidance, whereas vulnerable groups show limited capacity to adjust. Using air-quality forecasts, we find evidence of strategic intertemporal substitution, with consumers increasing current shopping when poor air quality is forecasted. Our findings reveal that air pollution generates behavioral responses in consumption, with implications for environmental policy and information provision.\n\n\n\nMoral Hazard in Agricultural Insurance - Evidence from Non-Voluntary Sow Insurance Program in China (with Xudong Rao and Yuehua Zhang)  Conditionally accepted at Australian Journal of Agricultural and Resource Economics\n\nAbstract: Agricultural insurance has not yet lived up to its full potential despite its apparent benefits to agricultural producers. Moral hazard is suspected to be a major obstacle to the adoption of agricultural insurance, especially livestock insurance. In this study, we take advantage of a government-supported, non-voluntary sow insurance program in China and examine whether farmers being aware of having insurance coverage leads to their hazardous behaviors. We estimate these impacts by using an endogenous treatment effects model which controls for endogeneity in our treatment variable. Our results are robust and suggest that farmers’ awareness of their insurance enrollment led to statistically and economically significant differences in their sow mortality rates. Therefore, our results demonstrate the presence of hazardous behavior.\n\n\n\nHow Importance is Junior High School Education Early in Life to Cognitive Outcomes of Elderlies: Evidence from A Quasi-Experiment in China (with Wen You and Yuehua Zhang)\n\nAbstract: As an important part of mental health, cognitive outcomes play a vital role in the quality of life for older adults. Identifying potential early life factors that can influence cognitive outcomes at older ages is of great public health importance. We examine the impact of obtaining junior high education early in life on the cognitive abilities of elderly individuals using a wave of longitudinal data set, the China Health and Retirement Longitudinal Study. We leverage the Cultural Revolution of 1966-1968 as a quasi-experiment identification strategy since this political event almost completely closed down junior high schools in China and created exogenous shocks to the relevant generation’s junior high education experience. We employed the instrumental variable and regression discontinuity methods using this political event as an instrument and discontinuity threshold respectively. Empirical results show that respondents who successfully obtained junior high school education early in life showed higher scores on all cognitive tests in later life. This research further excavates the long-term impact of the Cultural Revolution and provides evidence to support junior high education completion policies and programs for children.\n\n\n\n\nExtreme Weather Events and Farm Consolidation in the United States (with Metin Çakır)\nUnintended Doses: How Livestock Insurance Fuels Antibiotic Use on Chinese Hog Farms?(with Xudong Rao, Xingguo Wang, and Calum Turvey)\nSocietal Preferences for Donation to Rare Diseases: A Discrete Choice Experiment (with Wen Lin and Yuehua Zhang)\n\n\n\nQingyin Cai, Yulian Ding, Calumn Turvey, and Yuehua Zhang (2021). “The Influence of Past Experience on Farmers’ Preferences for Hog Insurance Products: a Natural Experiment and Choice Experiment in China.” The Geneva Papers on Risk and Insurance - Issues and Practice, 46: 399-421. [Link]"
  },
  {
    "objectID": "research.html#working-papers",
    "href": "research.html#working-papers",
    "title": "Qingyin Cai",
    "section": "",
    "text": "Drought and Fresh Produce Production in California (with Metin Çakır and Timothy Beatty)  R & R at Agricultural Economics\n\nAbstract: California’s increasingly frequent and intense drought is a pressing problem for the state’s agriculture and the U.S. food supply, as the state is the major producer of many agricultural products. Particularly, California supplies more than half of all fruit and vegetables in the country. This paper examines the severity of the problem by estimating the impacts of the drought on California’s fresh fruit and vegetable production. We estimate panel data models using comprehensive, county-level agriculture, irrigation, and weather data from 2000 to 2019. Our findings indicate that droughts significantly reduce total output, ranging from 1.2% to 2.2% for each additional week of drought. The estimated effect is driven by lower yields and fewer harvested acres due to the drought. The drought effects also differ among crops, with thirsty crops and crops with lower economic returns and established insurance programs being disproportionately affected. Results also show the extent to which higher irrigation levels mitigate the adverse effects of drought. Our findings provide insights into the importance of enhancing drought-related risk management and implications for designing cost-effective policies for future adaptation decisions.\n\n\n\nDrought and Farm Consolidation: Long-Run Evidence from U.S. Agriculture (with Metin Çakır)\n\nAbstract: In this study, we examine the long-run impacts of drought on farm consolidation in the U.S. crop sector from 1982-2022. Using four decades of county-level data and a long-difference design, we find that cumulative drought exposure significantly increases farm size, primarily through the exit of smaller farms. Effects are strongest in rainfed regions and among field crops, while specialty crop areas show weaker or negative responses to drought. These findings highlight drought as a structural force in U.S. agriculture and underscore the need for targeted climate adaptation policies.\n\n\n\nCalifornia Drought, Fresh Fruit and Vegetable Prices, and Consumer Welfare (with Metin Çakır, Timothy Beatty, and Timothy Park)\n\nAbstract: California produces more than a third of all vegetables and two-thirds of all fruits and nuts in the United States and is the largest producer of over fifty fruits, vegetables, and tree nuts. Meanwhile, California agriculture faces important challenges due to sustained drought with increasing frequency and severity across the state since 2011. This article estimates the effect of the recent California drought on the retail prices of fresh fruits and vegetables (FFV) using panel data models. We build a dataset comprising detailed information on FFV prices and the drought. Specifically, we construct a monthly panel price index for fresh fruits and vegetables using retail scanner data and obtain California’s county-level historical drought data from the United States Drought Monitor. In our estimation, we account for the heterogeneous effects of the drought across products and space. Our main finding is that the drought had a positive and significant effect on FFV prices. This effect is generally larger on fruits than vegetables and is robust to alternative measures of drought and model specifications. Furthermore, we find that the drought’s impacts on production and imports are among the significant determinants of its overall effect on prices.\n\n\n\nDoes the Recent Food Price Inflation Differ by Store Format? (with Metin Çakır and Megan Sweitzer)\n\nAbstract: Recent spikes in food prices have raised significant economic concerns in the United States. Understanding how food price inflation varies across store formats provides valuable insights into consumer behavior and the strategies retailers employ during economic downturns. In this study, we use retail scanner data to construct price indices by store format for various food product groups, allowing us to estimate differences in the rates of price changes across stores. We then estimate a structural store-choice model to examine how these differential rates of price changes affect consumers’ preferences for different store formats. Our findings reveal that food price inflation rates vary significantly by store format, with nontraditional stores generally experiencing lower inflation rates than traditional stores across most food categories. These differential price changes also influence consumer store and product choices.\n\n\n\nEmotional Shocks and Consumer Spending (with Qingxiao Li)  R & R at Journal of Economic Behavior & Organization\n\nAbstract: This study examines how emotional shocks affect consumer spending by using unexpected National Football League (NFL) game outcomes as a natural experiment. We analyze consumer scanner data from 83,332 households during regular seasons from 2004 to 2019, using Las Vegas pregame point spreads and actual outcomes to identify emotional shocks. We find that unexpected losses by home teams increase household shopping trips and spending, while unexpected wins reduce spending. These emotional impacts are concentrated within three days post-game and amplified for high-stakes games. These findings provide insights into how emotional shocks from unexpected events can influence consumer spending behavior.\n\n\n\nBad Air Days: Pollution, Forecasts, and Consumer Shopping Behavior (with Qingxiao Li and Lifeng Ren)\n\nAbstract: This paper provides nationwide evidence of how short-term exposure to fine particulate matter causally affects household retail shopping behavior in the United States. Linking detailed household transaction records with daily air quality data, we employ an instrumental-variable strategy that exploits exogenous, wind-driven variation in pollution. We find that air pollution reduces both store visits and retail spending. Consumers disproportionately reduce purchases of nonessential goods and partially shift toward online shopping. Higher-income and younger households show greater avoidance, whereas vulnerable groups show limited capacity to adjust. Using air-quality forecasts, we find evidence of strategic intertemporal substitution, with consumers increasing current shopping when poor air quality is forecasted. Our findings reveal that air pollution generates behavioral responses in consumption, with implications for environmental policy and information provision.\n\n\n\nMoral Hazard in Agricultural Insurance - Evidence from Non-Voluntary Sow Insurance Program in China (with Xudong Rao and Yuehua Zhang)  Conditionally accepted at Australian Journal of Agricultural and Resource Economics\n\nAbstract: Agricultural insurance has not yet lived up to its full potential despite its apparent benefits to agricultural producers. Moral hazard is suspected to be a major obstacle to the adoption of agricultural insurance, especially livestock insurance. In this study, we take advantage of a government-supported, non-voluntary sow insurance program in China and examine whether farmers being aware of having insurance coverage leads to their hazardous behaviors. We estimate these impacts by using an endogenous treatment effects model which controls for endogeneity in our treatment variable. Our results are robust and suggest that farmers’ awareness of their insurance enrollment led to statistically and economically significant differences in their sow mortality rates. Therefore, our results demonstrate the presence of hazardous behavior.\n\n\n\nHow Importance is Junior High School Education Early in Life to Cognitive Outcomes of Elderlies: Evidence from A Quasi-Experiment in China (with Wen You and Yuehua Zhang)\n\nAbstract: As an important part of mental health, cognitive outcomes play a vital role in the quality of life for older adults. Identifying potential early life factors that can influence cognitive outcomes at older ages is of great public health importance. We examine the impact of obtaining junior high education early in life on the cognitive abilities of elderly individuals using a wave of longitudinal data set, the China Health and Retirement Longitudinal Study. We leverage the Cultural Revolution of 1966-1968 as a quasi-experiment identification strategy since this political event almost completely closed down junior high schools in China and created exogenous shocks to the relevant generation’s junior high education experience. We employed the instrumental variable and regression discontinuity methods using this political event as an instrument and discontinuity threshold respectively. Empirical results show that respondents who successfully obtained junior high school education early in life showed higher scores on all cognitive tests in later life. This research further excavates the long-term impact of the Cultural Revolution and provides evidence to support junior high education completion policies and programs for children."
  },
  {
    "objectID": "research.html#work-in-progress",
    "href": "research.html#work-in-progress",
    "title": "Qingyin Cai",
    "section": "",
    "text": "Extreme Weather Events and Farm Consolidation in the United States (with Metin Çakır)\nUnintended Doses: How Livestock Insurance Fuels Antibiotic Use on Chinese Hog Farms?(with Xudong Rao, Xingguo Wang, and Calum Turvey)\nSocietal Preferences for Donation to Rare Diseases: A Discrete Choice Experiment (with Wen Lin and Yuehua Zhang)"
  },
  {
    "objectID": "research.html#publication",
    "href": "research.html#publication",
    "title": "Qingyin Cai",
    "section": "",
    "text": "Qingyin Cai, Yulian Ding, Calumn Turvey, and Yuehua Zhang (2021). “The Influence of Past Experience on Farmers’ Preferences for Hog Insurance Products: a Natural Experiment and Choice Experiment in China.” The Geneva Papers on Risk and Insurance - Issues and Practice, 46: 399-421. [Link]"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Qingyin Cai",
    "section": "",
    "text": "University of Minnesota (Minnesota, United States)\n\nGraduate Course\n\nIntroduction to R Statistical Analysis Software: Summer 2025\n\nLecture 0\nLecture 1\nLecture 2\nLecture 3\nLecture 4; Exercise\nLecture 5\n\n\n\n\n\n\nUniversity of Minnesota (Minnesota, United States)\n\nGraduate Course\n\nAPEC 8803 Applied Consumer Theory: Fall 2024\n\n\nInstitution Commercial Development International Business School (Shanghai, China)\n\nGraduate Course\n\nWelfare Economics: Fall 2020\n\n\n\n\n\nZhejiang University (Hangzhou, China)\n\nGraduate Course\n\nField Survey and Questionnaire Design: Spring 2019\n\n Undergraduate Course\n\nInsurance Economics: Fall 2018\nSocial Insurance: Fall 2017, Spring 2020\n\n\n\n\n\nUniversity of Minnesota (Minnesota, United States)\n\nIncoming Ph.D. Student Mentor, Deparment of Applied Economcis: 2022-2024"
  },
  {
    "objectID": "teaching.html#instructor",
    "href": "teaching.html#instructor",
    "title": "Qingyin Cai",
    "section": "",
    "text": "University of Minnesota (Minnesota, United States)\n\nGraduate Course\n\nIntroduction to R Statistical Analysis Software: Summer 2025\n\nLecture 0\nLecture 1\nLecture 2\nLecture 3\nLecture 4; Exercise\nLecture 5"
  },
  {
    "objectID": "teaching.html#guest-lecturer",
    "href": "teaching.html#guest-lecturer",
    "title": "Qingyin Cai",
    "section": "",
    "text": "University of Minnesota (Minnesota, United States)\n\nGraduate Course\n\nAPEC 8803 Applied Consumer Theory: Fall 2024\n\n\nInstitution Commercial Development International Business School (Shanghai, China)\n\nGraduate Course\n\nWelfare Economics: Fall 2020"
  },
  {
    "objectID": "teaching.html#teaching-assistant",
    "href": "teaching.html#teaching-assistant",
    "title": "Qingyin Cai",
    "section": "",
    "text": "Zhejiang University (Hangzhou, China)\n\nGraduate Course\n\nField Survey and Questionnaire Design: Spring 2019\n\n Undergraduate Course\n\nInsurance Economics: Fall 2018\nSocial Insurance: Fall 2017, Spring 2020"
  },
  {
    "objectID": "teaching.html#mentor",
    "href": "teaching.html#mentor",
    "title": "Qingyin Cai",
    "section": "",
    "text": "University of Minnesota (Minnesota, United States)\n\nIncoming Ph.D. Student Mentor, Deparment of Applied Economcis: 2022-2024"
  },
  {
    "objectID": "Lec0.html#outline",
    "href": "Lec0.html#outline",
    "title": "Day 1: Introduction to R Statistical Analysis Software",
    "section": "Outline",
    "text": "Outline\n\nIntroduction\n\nCourse Review\n\nIcebreaker\n\n\n\nMotivation\n\nWhat you can do with R?\nHow do we use R in course in APEC?\nBasic knowledge about R and Rstudio"
  },
  {
    "objectID": "Lec0.html#course-overview",
    "href": "Lec0.html#course-overview",
    "title": "Day 1: Introduction to R Statistical Analysis Software",
    "section": "Course overview",
    "text": "Course overview\n\nIntroStyleReferences\n\n\n\nThis one-week course is a boot camp designed to introduce you to R statistical software. My goal is to build a strong foundation for your Ph.D.-level econometrics courses and future research.\n\nBy the end of this week, you will be able to:\n\nto create and manipulate the base-R object data.\nto do data manipulation with data.table package.\nto do data visualization with ggplot2 package.\nto conduct regression analysis with lm() and make a publish-ready regression table with modelsummary() package.\nto write Monte code for Carlo simulations using for loop function.\n\n\n\n\n\nWe will meet each day from 1:00 PM to 4:00 PM, with office hours immediately following.\nEach lecture is divided into three sessions, with each session consisting of a 50-minute lecture and a 10-minute break.\nWe will have in-class exercises at the end of each topic, and after-class exercises (optional) to practice!\n\n\n\nNo textbook is required. Below are recommended resources:\n\n\nRecommended Reading\n\nR for Data Science\n\nggplot2 Book\n\nIntro to data.table\n\nIntro to Econometrics with R\n\n\n\nEssential Cheatsheets\n\nBase R\n\ndata.table\n\nggplot2\n\nR Markdown"
  },
  {
    "objectID": "Lec0.html#about-myself",
    "href": "Lec0.html#about-myself",
    "title": "Day 1: Introduction to R Statistical Analysis Software",
    "section": "About myself",
    "text": "About myself\n\nQingyin Cai\n\nFrom China\nFifth-year Ph.D. in Applied Economics\nArea of interests: Food and Agriculture Economics, Consumer Economics, and Environment Economics.\n\n\n\n\nIntroduce yourself\n\nWhat’s your name?\nWhat’s your program?\nWhere are you from?\nWhat brings you to UMN?"
  },
  {
    "objectID": "Lec0.html#what-is-r",
    "href": "Lec0.html#what-is-r",
    "title": "Day 1: Introduction to R Statistical Analysis Software",
    "section": "What is R?",
    "text": "What is R?\n\nR is a powerful programming language for a wide range of tasks:\n\nData Manipulation: cleaning, reshaping, merging datasets, API.\n\nVarious Analysis: descriptive analysis, regression, GIS, spatial analysis, machine learning.\n\nData visualization.\n\nIt’s a great tool to communicate your results with others (documentation, papers, slides, books, etc.).\n\nComparison of R, Stata, and Python\n\n\n\n\n\n\n\n\n\nCriteria\nR\nStata\nPython\n\n\n\n\nPrimary Use\nStatistical analysis, visualization, research\nEconomics/social science research; valued for tested results\nGeneral-purpose; machine learning, web scraping, automation\n\n\nCost\nOpen-source\nCommercial license\nOpen-source\n\n\nData Visualization\nExcellent\nLess flexible or aesthetically pleasing\nVery powerful, but can be verbose\n\n\nEcosystem\nLarge academic community; many packages on CRAN\nStrong in economics but smaller user base\nHuge, diverse community\n\n\nHandling Big Data\nBase R is memory-bound; packages like data.table / arrow improve performance\nMemory-bound\nExcellent"
  },
  {
    "objectID": "Lec0.html#ai-and-learning-r",
    "href": "Lec0.html#ai-and-learning-r",
    "title": "Day 1: Introduction to R Statistical Analysis Software",
    "section": "AI and Learning R",
    "text": "AI and Learning R\n\nAI can help, but it cannot replace understanding.\n\nTools like ChatGPT or Copilot can generate R code, but you need to know if the code is correct and appropriate.\n\nYou’ll understand why a method works, not just how to run it.\n\nAcademic integrity & skill development.\n\nEmployers and researchers may expect you to adapt and debug code yourself.\n\nLong-term benefit.\n\nOnce you know R, AI becomes a more powerful assistant — you can ask better questions and spot mistakes."
  },
  {
    "objectID": "Lec0.html#r-in-the-apec-curriculum",
    "href": "Lec0.html#r-in-the-apec-curriculum",
    "title": "Day 1: Introduction to R Statistical Analysis Software",
    "section": "R in the APEC curriculum",
    "text": "R in the APEC curriculum\n\nWe use R extensively in the Econometrics series (APEC 8211-8214).\n\nTo conduct regression analysis (OLS, IV, FE, etc.).\n\nTo conduct Monte Carlo simulations.\n\ne.g., To understand the difference in variance inference techniques.\n\n\n\nDon’t worry if you are new to this!\n\nBasic knowledge is enough to start.\n\nIf you would like to learn R programming further, I recommend that you take Programming for Econometrics (APEC8221) and Big Data Methods in Economics (APEC8222)."
  },
  {
    "objectID": "Lec0.html#rstudio",
    "href": "Lec0.html#rstudio",
    "title": "Day 1: Introduction to R Statistical Analysis Software",
    "section": "Rstudio",
    "text": "Rstudio\n\n\nWhat is it?Create New R code FileChange the theme (Optional)Multiple panes (Optional)Command Palette (Optional)\n\n\n\nYou can use  app to write and run R codes, but it has a terrible graphic user interface.\nRstudio is an Integrated Development Environment. It provides a user-friendly interface to write and run R code, view plots, and manage files.\nYou must install R (the engine) before you can use RStudio!\nR studio looks like this:\n\n\n\n\nImage Source: Rstudio User Guide\n\n\n\n\n\nTo create new R script file, click the + button on the top-left corner of the Rstudio, or hit Ctrl + Shift + N (Cmd + Shift + N on mac).\nTo save the file, click the floppy disk icon , or Ctrl + S (Cmd + S on macOS).\n\n\n\n\nImage Source: Rstudio User Guide\n\n\n\n\n\nYou can change the appearance of Rstudio by going to Tools -&gt; Global Options -&gt; Appearance -&gt; Editor theme and select your favorite theme.\n\n\n\n\nImage Source: Rstudio User Guide\n\n\n\n\n\nYou can have multiple code panes in Rstudio.\n\nTo create a new pane, go to Tools -&gt; Global Options -&gt; Pane Layout -&gt; Add Column.\n\nIn the same window, you can also change the layout of the panes.\n\n\n\n\n\n\n\n\n\nRecent R-studio has a new feature called “Command Palette.”\n\nHit Ctrl + Shift + P (Cmd + Shift + P on macOS) on your keyboard, or go to Tools -&gt; Show Command Palette.\nFrom here, you can search for and do almost anything: create new files, open projects, etc.\n\n\n\n\nSource: Rstudio User Guide"
  },
  {
    "objectID": "Lec0.html#rstudio-running-code",
    "href": "Lec0.html#rstudio-running-code",
    "title": "Day 1: Introduction to R Statistical Analysis Software",
    "section": "Rstudio: Running Code",
    "text": "Rstudio: Running Code\nLet’s write some codes.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nR code\n\nAny thing you write in the source (or console) pane is regarded as R code.\n\nTo run (execute) the code, select the code line, and click the “Run” bottom, or use the shortcut key: Ctrl + Enter (Cmd + Enter on macOS).\n\nComment block\n\nAny line starting with a # is a comment. R will ignore it. Use comments to leave notes for yourself and others!"
  },
  {
    "objectID": "Lec0.html#summary",
    "href": "Lec0.html#summary",
    "title": "Day 1: Introduction to R Statistical Analysis Software",
    "section": "Summary",
    "text": "Summary\n\n\nYou are now familiar with the basics of RStudio. As long as you know how to create, save, and run a script, you are ready for the next lecture.\nFor more details, see the official RStudio IDE Cheatsheet.\nWhile RStudio is the most popular tool, you can also run R in other editors like Visual Studio Code to run R. Nevertheless, Rstudio is a great starting point to get familiar with R."
  },
  {
    "objectID": "Lec3.html#section",
    "href": "Lec3.html#section",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "",
    "text": "Learning Objectives\n\nLearn the basic operations of ggplot2 package to create figures.\nYou will be able to create:\n\nscatter plot\nline plot\nbar plot\nhistogram\nbox plot\ndensity plot\nfacet plot\n\n\n\n\n\n Reference\n\nggplot2: Elegant Graphics for Data Analysis (3e)\nR for Data Science (2e), Ch1: Data Visualization"
  },
  {
    "objectID": "Lec3.html#todays-outline",
    "href": "Lec3.html#todays-outline",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "\n Today’s Outline:",
    "text": "Today’s Outline:\n\nTaste of ggplot2 package\n\nIntroduction to ggplot 2\n\nAnatomy of ggplot2\nScatter Plot\nDifferent Types of Plot\nModify Aesthetic Attributes\nGroup Aesthetic\nCollective geoms\nModify Axis, Labels, and Titles\n\n\n\nAdvanced Topics\n\nFacet Plot\nMultiple Datasets in One Figure\nggplot2 Themes\ntheme() Function\nSave the Plot"
  },
  {
    "objectID": "Lec3.html#taste-of-ggplot2-package",
    "href": "Lec3.html#taste-of-ggplot2-package",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Taste of ggplot2 package",
    "text": "Taste of ggplot2 package\nBy the end of the lecture, you will be able to create the figures like the following examples using ggplot2 package.\n\n\nExample 1\nExample 2\nExample 3\nExample 4\nExample 5"
  },
  {
    "objectID": "Lec3.html#section-1",
    "href": "Lec3.html#section-1",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "",
    "text": "There are many functions in the ggplot2 package to create figures, and today’s lecture is not a comprehensive guide to all of them.\nWe will focus on the basic functions to create the most common types of figures."
  },
  {
    "objectID": "Lec3.html#before-starting",
    "href": "Lec3.html#before-starting",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Before Starting",
    "text": "Before Starting\nInstall the package ggplot2 and gapminder locally if you haven’t already done so.\n\ninstall.packages('ggplot2')\ninstall.packages('gapminder')\n\nOnce you have the package in R, let’s load it.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nNote\n\nThere is a package called tidyverse, which is a collection of R packages designed for data science.\nWhen you load the tidyverse package, the ggplot2 package is automatically loaded."
  },
  {
    "objectID": "Lec3.html#intro",
    "href": "Lec3.html#intro",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Introduction to ggplot2\n",
    "text": "Introduction to ggplot2\n\n\n\nWhat is it?\nHow does it work?\n\n\n\n\nAs you know, there are already base (built-in) R functions to create figures (e.g., plot() and hist())\n\npros: they are fast (especially for plotting a large dataset).\ncons: The plots are difficult to customize.\n\n\n\n\n\nThe ggplot2 package provides more flexibility and customization options for creating figures with consistent syntax.\n\nCheck this out to see what kind of figures ggplot2 can make.\n\n\nVariety of extensional packages built on top of ggplot2 (e.g., ggthemes, ggpubr, ggrepel, gganimate, etc.) allows you to create more complex figures.\n\nSee this for examples.\n\n\n\n\n\n\n\nggplot2 views a figure as the collection of multiple independent layers.\n\nlayers for geometric objects (e.g., points, lines, bars), layers for aesthetic attributes of the geometric objects (color, shape, size), layers of annotations and statistical summaries, … etc.\n\n\nThen, it combines these layers to create a single figure as a final output."
  },
  {
    "objectID": "Lec3.html#anatomy-of-ggplot2",
    "href": "Lec3.html#anatomy-of-ggplot2",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Anatomy of ggplot2",
    "text": "Anatomy of ggplot2\n\n\nUse the right-arrow (or down-arrow) key to move through the steps. The left column shows the code. The right column shows the plot it produces. Watch how the plot changes each time a new line of code is added.\n\n\n\n\n\n\n# Create a canvas for the plot\nggplot(data = airquality) \n\n\n\n\n\n\n\n\n\n\n\n\n# Create a canvas for the plot\nggplot(data = airquality) + \n  # Add x-axis\n  aes(x = Wind)\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a canvas for the plot\nggplot(data = airquality) + \n  # Add x-axis\n  aes(x = Wind) +\n  # Add y-axis \n  aes(y = Ozone) \n\n\n\n\n\n\n\n\n\n\n\n\n# Create a canvas for the plot\nggplot(data = airquality) + \n  # Add x-axis\n  aes(x = Wind) + \n  # Add y-axis\n  aes(y = Ozone) +\n  # Add a scatter plot\n  geom_point() \n\n\n\n\n\n\n\n\n\n\n\n\n# Create a canvas for the plot\nggplot(data = airquality) + \n  # Add x-axis\n  aes(x = Wind) +\n  # Add y-axis\n  aes(y = Ozone) + \n  # Add a scatter plot\n  geom_point() +\n  # Add a regression line\n  geom_smooth(method = \"lm\") \n\n\n\n\n\n\n\n\n\n\n\n\n# Create a canvas for the plot\nggplot(data = airquality) + \n  # Add x-axis\n  aes(x = Wind) +\n  # Add y-axis\n  aes(y = Ozone) + \n  # Add a scatter plot\n  geom_point() +\n  # Add a regression line\n  geom_smooth(method = \"lm\") +\n  # Change x-axis label\n  labs(x = \"Wind Speed (mph)\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a canvas for the plot\nggplot(data = airquality) + \n  # Add x-axis\n  aes(x = Wind) +\n  # Add y-axis\n  aes(y = Ozone) + \n  # Add a scatter plot\n  geom_point() +\n  # Add a regression line\n  geom_smooth(method = \"lm\") +\n  # Change x-axis label\n  labs(x = \"Wind Speed (mph)\") +\n  # Change y-axis label\n  labs(y = \"Ozone (ppb)\") \n\n\n\n\n\n\n\n\n\n\n\n\n# Create a canvas for the plot\nggplot(data = airquality) + \n  # Add x-axis\n  aes(x = Wind) +\n  # Add y-axis\n  aes(y = Ozone) + \n  # Add a scatter plot\n  geom_point() +\n  # Add a regression line\n  geom_smooth(method = \"lm\") +\n  # Change x-axis label\n  labs(x = \"Wind Speed (mph)\") +\n  # Change y-axis label\n  labs(y = \"Ozone (ppb)\") +\n  # Add title and subtitle\n  labs(\n    title = \"Relationship between ozone and wind speed in New York\",\n    subtitle = \"May to September 1973\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a canvas for the plot\nggplot(data = airquality) + \n  # Add x-axis\n  aes(x = Wind) +\n  # Add y-axis\n  aes(y = Ozone) + \n  # Add a scatter plot\n  geom_point() +\n  # Add a regression line\n  geom_smooth(method = \"lm\") +\n  # Change x-axis label\n  labs(x = \"Wind Speed (mph)\") +\n  # Change y-axis label\n  labs(y = \"Ozone (ppb)\") +\n  # Add title and subtitle\n  labs(\n    title = \"Relationship between ozone and wind speed in New York\",\n    subtitle = \"May to September 1973\"\n  ) +\n  # Add caption\n  labs(caption = \"Data source:\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a canvas for the plot\nggplot(data = airquality) + \n  # Add x-axis\n  aes(x = Wind) +\n  # Add y-axis\n  aes(y = Ozone) + \n  # Add a scatter plot\n  geom_point() +\n  # Add a regression line\n  geom_smooth(method = \"lm\") +\n  # Change x-axis label\n  labs(x = \"Wind Speed (mph)\") +\n  # Change y-axis label\n  labs(y = \"Ozone (ppb)\") +\n  # Add title and subtitle\n  labs(\n    title = \"Relationship between ozone and wind speed in New York\",\n    subtitle = \"May to September 1973\"\n  ) +\n  # Add caption\n  labs(caption = \"Data source:\") +\n  # Set the theme\n  theme_bw() \n\n\n\n\n\n\n\n\n\n\n\n\n# Create a canvas for the plot\nggplot(data = airquality) + \n  # Add x-axis\n  aes(x = Wind) +\n  # Add y-axis\n  aes(y = Ozone) + \n  # Add a scatter plot\n  geom_point() +\n  # Add a regression line\n  geom_smooth(method = \"lm\") +\n  # Change x-axis label\n  labs(x = \"Wind Speed (mph)\") +\n  # Change y-axis label\n  labs(y = \"Ozone (ppb)\") +\n  # Add title and subtitle\n  labs(\n    title = \"Relationship between ozone and wind speed in New York\",\n    subtitle = \"May to September 1973\"\n  ) +\n  # Add caption\n  labs(caption = \"Data source:\") +\n  # Set the theme\n  theme_bw() +\n  # Center the title and subtitle position\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote: This code is for demonstration purposes. Don’t imitate this code!"
  },
  {
    "objectID": "Lec3.html#anatomy-of-ggplot2-continued",
    "href": "Lec3.html#anatomy-of-ggplot2-continued",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Anatomy of ggplot2 (continued)",
    "text": "Anatomy of ggplot2 (continued)\n\nEvery ggplot2 plot has three key components:\n\nData\n\nA set of aesthetic mappings between variables in the data and visual properties.\nAt least one layer which describes how to render each observation. Layers are usually created with a geom function.\n\n\n\n\nThe very general syntax for creating a plot with ggplot2 is as follows:\n\nggplot(data = ...) +\n  geom_*(aes( ... ))\n\n\n\n\naes stands for aesthetic mappings. It tells ggplot2 how to map variables in the data to visual properties of the plot (e.g., x-axis, y-axis, color, shape, size, etc.)\n\n+ operator tells R that you’re adding another layer (e.g., line plot) to the current “canvas”.\nDepending on the type of the figure you want to plot, use different geom_*() functions.\n\nEg. geom_point() for scatter plot, geom_line() for line plot, etc."
  },
  {
    "objectID": "Lec3.html#example",
    "href": "Lec3.html#example",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Example",
    "text": "Example\n\n\nData\nLet’s Create a Scatter Plot\nStep 1\nStep 2\n\n\n\nLet’s use the airquality data for this example.\n\n\nairquality data is a built-in dataset in R. So, you don’t need to load it.\nType airquality in the console to see the data. (Type ?airquality in the console for more information.)\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nWe will create a scatter plot of Ozone (ozone level in the air) and Temp (Maximum daily temperature in degrees \\(F\\)) from the airquality data.\nThe final plot should look like the following:\n\n\n\n\n\n\n\n\n\n\nStep 1: Start with ggplot()\n\n\nggplot(data = dataset) initializes a ggplot object. In other words, it prepares a “canvas” for the plot.\nHere, let R know the dataset you are trying to visualize.\n\n\n\nTry it!\nWhy?\n\n\n\nRun the following code. Can you see any output?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nThis code does not produce any output because we haven’t told R what to plot with the data yet.\n\nggplot() just prepares a blank “canvas” for you!\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nStep 2: Draw figures with geom_*() functions, and add to the current canvas use + operator\n\n\nFor example, we use geom_point() to create a scatter plot.\n\nuse aes() to specify which variable you want to use for x and y axis.\n\n\naes() is used to tell R to look for the variables inside the dataset you specified in ggplot(), and use the information as specified.\ne.g., aes(x = Temp, y = Ozone) tells R to look for Temp and Ozone in the data, and to map the data to x-axis and y-axis, respectively.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec3.html#summary",
    "href": "Lec3.html#summary",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Summary",
    "text": "Summary\nThese are basic steps to create a figure with ggplot2 package.\n\nStep1: Start with ggplot()\n\nThis function prepares a “canvas” for the figure.\n\n\nStep2: Draw a figure with geom_*() function, and add to the current canvas with + operator.\nStep3: Repeat Step2 and Step3 to add whatever layers you want to add.\nStep4 (optional): Add labels, titles, and other annotations to the plot with labs(), theme(), etc.\n\n\n\nDon’t forget to specify x and y variables in the aes() function.\n\nAlso, some geom_*() functions only require x variable (e.g., geom_histogram()).\n\n\nIn step 3, layers can be added in any order, but the order of the layers affects the final appearance of the plot.\n\nWhen you want to make a simple x and y plot, the base R functions are sufficient (e.g., with(data, plot(column_x, column_y))"
  },
  {
    "objectID": "Lec3.html#exercise-problems1",
    "href": "Lec3.html#exercise-problems1",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "In-class exercise",
    "text": "In-class exercise\n\n\nQuestions\nAnswers\n\n\n\n\nCreate a scatter plot of Temp and Wind from the airquality data.\nIn the plot you just created, let’s change the x-axis label to “Maximum temperature (degrees F)” and the y-axis label to “Wind Speed (mph)”. For this, use labs() function.\n\nHint:\n\nlabs(x = new_x_label, y = new_y_label)\nuse + to add this layer to the plot.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nCreate a scatter plot of Temp and Wind from the airquality data.\nIn the plot you just created, let’s change the x-axis label to “Maximum temperature (degrees F)” and the y-axis label to “Wind Speed (mph)”. For this, use labs() function.\n\nHint:\n\nlabs(x = new_x_label, y = new_y_label)\nuse + to add this layer to the plot.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec3.html#different-types-of-plot",
    "href": "Lec3.html#different-types-of-plot",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Different Types of Plot",
    "text": "Different Types of Plot\n\nYou can create various plots with the ggplot2 package by choosing the appropriate geom_*() function for the desired plot type.\n\nHere are some of the most commonly used geom_*() functions.\n\n\ngeom_point(): scatter plot\n\ngeom_line(): line plot\n\ngeom_bar(): bar plot\n\ngeom_boxplot(): box plot\n\ngeom_histogram(): histogram\n\ngeom_density(): density plot\n\nThis computes and draws kernel density estimates, and is a smoothed version of the histogram.\n\n\n\ngeom_smooth(): draws an OLS-estimated regression line (other regression methods available) \n\n\n\nsee this for full list of geom_*()"
  },
  {
    "objectID": "Lec3.html#modify-aesthetic-attributes",
    "href": "Lec3.html#modify-aesthetic-attributes",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Modify Aesthetic Attributes",
    "text": "Modify Aesthetic Attributes\n\n\n\nBasics\nExamples\n\n\n\nWe can modify how plots look by specifying color, shape, and size.\nHere are list of options to control the aesthetics of figures. You use these options inside the geom_*().\n\n\nsize: control the size of points and text\n\ne.g., geom_point(size = 3)\n\n\n\n\ncolor: control color of the points and lines\n\ne.g.,geom_point(color = \"blue\")\n\n\n\n\nfill: control the color of the inside areas of figures like bars and boxes\n\ne.g., geom_density(fill = \"blue\") fills the area under the density curve with blue color\n\n\n\nalpha controls the transparency of the fill color\n\ne.g., alpha=1 is opaque, alpha=0 is completely transparent, usually between 0 and 1\n\n\n\nshape: controls the symbols of point, it takes integer values between 0 and 25\n\ne.g., geom_point(shape = 1) for circle, geom_point(shape = 2) for triangle\n\n\n\n\n\nFor point shapes available in R, see this.\n\nFor further information about the options for aesthetics, see this.\n\n\n\n\n\n\nScatter Plot\nHistogram\nLine Plot\n\n\n\n\n\nsize = 3: makes the points larger.\n\ncolor = \"red\": changes the color of the points to red.\n\nshape = 1: changes the shape of the points to circle.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nfill = \"blue\": fills the bars with blue color.\n\nalpha = 0.5: makes the fill color semi-transparent.\n\nTry changing the value of alpha to see how the transparency changes.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nlinewidth = 1.5: makes the line thicker.\n\ncolor = \"purple\": changes the color of the line to purple.\n\nlinetype = \"dotted\": changes the line type to dotted.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec3.html#exercise-problems2",
    "href": "Lec3.html#exercise-problems2",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "In-class Exercise",
    "text": "In-class Exercise\n\n\n\nExercise 1\nExercise 2\n\n\n\n\n\nQuestions\nAnswers\n\n\n\nCreate a density plot of Ozone from the airquality data. Fill the area under the density curve with blue and make it semi-transparent (use alpha = 0.5).\nThe figure should look like the following:\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\nQuestions\nAnswers\n\n\n\n\n\nCreate box plots of monthly Temp from the airquality data. Fill the boxes with green and make it semi-transparent (use alpha = 0.5).\nThe figure should look like the following:\n\nHint\n\nThis is a bit of a tricky problem, but very useful!\nWe want to use Month as a categorical variable for the x-axis, but Month is a numeric variable in the data. How can we tell R to use it as a categorical (factor) variable?\n\nApply factor() function to a Month to convert it to a factor variable in aes() in the geom_*() function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec3.html#group-aesthetic",
    "href": "Lec3.html#group-aesthetic",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Group Aesthetic",
    "text": "Group Aesthetic\n\n\n\nBasics\nIn-class Exercise\n\n\n\nSo far, we specified aesthetic attributes outside of the aes() function. Consequently, all the geometric objects in the plot have the same color, shape, and size, etc.\n\ne.g., geom_point(aes(x = var_x, y = var_y), color = \"red\").\n\nIf you use those options inside the aes() function like aes(color = var_z), R will display different colors by group based on the value of var_z. Usually var_z is a categorical variable.\n\ne.g., geom_point(aes(x = var_x, y = var_y, color = var_z)) displays a scatter plot where the points are colored differently based on the value of var_z.\n\nExample\nLet’s create density plots of Temp for each month, and use different colors (fill in this case) for different Month.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nQuestions\nAnswers\n\n\n\n\nCreate a scatter plot of Ozone and Temp in the airquality data. Let’s use different colors for different Month.\nIn addition to the previous plot, let’s use different shapes for different Month.\n\nNOTE: Remember that we need to tell R to use Month as a categorical variable.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nCreate a scatter plot of Ozone and Temp in the airquality data. Let’s use different colors for different Month.\nIn addition to the previous plot, let’s use different shapes for different Month.\n\nNOTE: Remember that we need to tell R to use Month as a categorical variable.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec3.html#collective-geoms",
    "href": "Lec3.html#collective-geoms",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Collective geoms",
    "text": "Collective geoms\n\n\n\nBasics\nExample\n\n\n\nSo far, we used only one geom_*() function in a plot. But you can use multiple geom_*() functions in a single plot.\n\nThis just overlays multiple layers of different geometric objects on the same “canvas”.\nUse + operator to add multiple geom_*() functions to the plot.\n\nExample Syntax\n\nggplot(data = dataset) +\n  geom_*(aes(x = column_x, y = column_y, fill = column_z)) +\n  geom_*(aes(x = column_x, y = column_y)) +\n  geom_*(aes(x = column_x, y = column_y)) +\n  ...\n\nIf an additional layer has the same aes() mapping, you can specify it only once in the ggplot().\n\n# The above code is equivalent to the following code\nggplot(data = dataset, aes(x = column_x, y = column_y) +\n  geom_*(fill = column_z)) +\n  geom_*() +\n  geom_*() +\n  ...\n\nNote\n\nRecall that ggplot() prepares a plot object.\nIf you tell ggplot() to use aes() mapping from the beginning, you don’t need to specify it again in the geom_*() functions.\n\n\n\n\nLet’s create a scatter plot of Ozone and Temp from the airquality data.\nIn addition to the scatter plot, let’s add a simple regression line to the plot using geom_smooth() function.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec3.html#modify-axis-legend-plot-labels",
    "href": "Lec3.html#modify-axis-legend-plot-labels",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Modify Axis, Legend, and Plot Labels",
    "text": "Modify Axis, Legend, and Plot Labels\n\n\n\nBasics\nExamples\n\n\n\n\nBy default, x-axis, y-axis, and legend labels are the column names of the data, which are not always informative. Also, you might want to add a title and subtitle to the plot.\nYou can modify the labels, titles, and other annotations of the plot using labs() function.\n\nExample Syntax\n\nggplot(data = dataset) +\n  geom_*(aes(x = column_x, y = column_y)) +\n  labs(\n    x = \"X-axis label\",\n    y = \"Y-axis label\",\n    title = \"Title of the plot\",\n    subtitle = \"Subtitle of the plot\",\n    caption = \"Data source\"\n  )\n\n\n\n\n\n\nExample 1\nExample 2\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nNote\n+ If you use color (fill) for group aesthetic, you need to use color (fill) in the labs() function to change the legend title."
  },
  {
    "objectID": "Lec3.html#summary-1",
    "href": "Lec3.html#summary-1",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Summary",
    "text": "Summary\n\nLet’s summarize what we have learned so far. \n\nthe basic syntax of the ggplot2 package.\nhow to create a popular types of plots (scatter plot, line plot, bar plot, histogram, box plot, density plot).\nhow to modify aesthetic attributes of the plot (color, shape, size, etc.)\nhow to use group aesthetic to group the data by a variable\nhow to use multiple geom_*() functions in a single plot.\nhow to modify axis, legend, and plot labels with labs() function."
  },
  {
    "objectID": "Lec3.html#exercise-problems",
    "href": "Lec3.html#exercise-problems",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Exercise Problems",
    "text": "Exercise Problems\n\n\n\nExercise Problems 1\nExercise Problems 2\n\n\n\n\n\n\nData\nInstructions\nSolutions\n\n\n\nLet’s use the economics data, which is a dataset built into the ggplot2 package. It was produced from US economic time series data available from Federal Reserve Economic Data. This contains the following variables:\n\n\ndate: date in year-month format\n\npce: personal consumption expenditures, in billions of dollars\n\npop: total population in thousands\n\npsavert: personal savings rate\n\nuempmed: median duration of unemployment in weeks\n\nunemploy: number of unemployed in thousands\n\n\n\n1. Create a scatter plot of unemploy (x-axis) and psavert (y-axis). Add a simple regression line to the plot. Change the x-axis, y-axis, and fill legend labels to something more informative.\n2. Create a bar plot of psavert by date. Use pop for fill color. Change the x-axis, y-axis, and fill legend labels to something more informative.\n\n\nHint: use stat = 'identity' in the geom_bar() function to plot the actual values of pce.\n\n3. (Challenging) Create a multiple line plot taking day as x-axis and psavert and uempmed as y-axis, respectively. The output should look like the following.\n\n\nHint: I think there are multiple ways to do this.\n\n\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\nData\nInstructions\nSolutions\n\n\n\nFor this exercise problem, we will use medical cost personal datasets descried in the book “Machine Learning with R” by Brett Lantz. The dataset provides \\(1,338\\) records of medical information and costs billed by health insurance companies in 2013, compiled by the United States Census Bureau.\nThe dataset contains the following variables:\n\n\nage: age of primary beneficiary\n\nsex: insurance contractor gender, female, male\n\nbmi: body mass index, providing an understanding of body, weights that are relatively high or low relative to height\n\nchildren: number of children covered by health insurance\n\nsmoker: smoking\n\nregion: the beneficiary’s residential area in the US; northeast, southeast, southwest, northwest.\n\ncharges: individual medical costs billed by health insurance\n\nDownload the data\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nCreate a histogram of charges by sex in the same plot. Fill the boxes with different colors for each sex.\nCreate a scatter plot of bmi (x-axis) and charges (y-axis).\nNow, create a scatter plot of bmi (x-axis) and charges (y-axis), and add regression lines by smoke (So, there are two regression lines: one for group of smokers and the other for group of non-smokers).\nCreate the following plot.\n\n\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec3.html#before-we-start",
    "href": "Lec3.html#before-we-start",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Before We Start",
    "text": "Before We Start\nFor this section, we will continue to use the economics and insurance data we used in the previous exercise problems."
  },
  {
    "objectID": "Lec3.html#facet-plot",
    "href": "Lec3.html#facet-plot",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Facet Plot",
    "text": "Facet Plot\n\n\n\nIntro\nfacet_wrap()\nfacet_grid()\n\n\n\nYou can partition a plot into a matrix of panels and display a different subset of the data in each panel. This is useful when you want to compare patterns in the data by group.\n\n\n\nExample 1\nExample 2\n\n\n\n\n\n\n\n\nWithout faceting\n\n\n\n\n\n\n\n\nBecause the scales of the y-axis are different by variable, it is hard to compare the trends across variables in the same plot.\n\nWith faceting\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere, I am showing the distribution of charges by sex and region in the same plot.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfacet_wrap() makes a long ribbon of panels (generated by any number of variables). You can also wrap it into 2 rows.\nSyntax:\n\nfacet_wrap(vars(var_x, var_y), scales = \"fixed\", nrow = 2, ncol = 2)\n\n\nInside vars(), specify variables used for faceting groups.\n\nncol and nrow control the number of columns and rows (you only need to set one).\n\nscales controls the scales of the axes in the panel (either \"fixed\" (the default), \"free_x\", or \"free_y\", \"free\").\n\n\nTry it!\nPlay around with the facet_wrap() function in the code below. See how the choice of faceting groups, number of rows and columns and the scales of the axes affect the appearance of the plot.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nfacet_grid() produces a 2 row grid of panels defined by variables which form the rows and columns.\nSyntax:\n\nfacet_grid(rows = vars(var_x), cols = var(var_y)), scales = \"fixed\")\n\n\nThe graph is partitioned by the levels of the groups var_x and var_y in the rows and columns, respectively.\n\nncol and nrow control the number of columns and rows (you only need to set one).\n\nscales controls the scales of the axes in the panel (either fixed (the default), free_x, or free_y, free).\n\n\nTry it!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec3.html#facet_wrap-vs-facet_grid",
    "href": "Lec3.html#facet_wrap-vs-facet_grid",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "facet_wrap() vs facet_grid()",
    "text": "facet_wrap() vs facet_grid()\n\n\n\nBasics\nExample\n\n\n\nSo, when should you use facet_wrap() and facet_grid()?\n\nIn my opinion, if you have a single variable to make a facet, you should use facet_wrap(). Unlike facet_grid(), facet_wrap() can control the number of rows and columns in the panel.\nIf you have two variables to make a facet, you should use facet_grid().\nIn facet_grid(), you don’t always need to provide both rows and columns variables. If only one is specified, the produced plot will look like the one from facet_wrap() but you cannot wrap the panels into 2 rows.\n\n\n\n\n\n\nOne Faceting Variables\nTwo Faceting Variables\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec3.html#how-can-we-modify-the-facet-labels",
    "href": "Lec3.html#how-can-we-modify-the-facet-labels",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "How can we modify the facet labels?",
    "text": "How can we modify the facet labels?\nSee the following document: How can I set different axis labels for facets?. You can use the labeller argument in the facet_wrap() and facet_grid() function to modify the facet labels.\nHere, I will show another way to modify the facet labels. You can\n\n\n\nPreparation\nfacet_wrap\nfacet_grid\n\n\n\nFirst, I re-define region and sex as factor variables. In doing so, I will add labels for each level of the variables. If labels are attached to the variables, ggplot use those names in the facet labels.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nNow, the facet labels are changed to “North East”, “North West”, “South East”, and “South West” for the region variable.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec3.html#multiple-datasets-in-one-figure",
    "href": "Lec3.html#multiple-datasets-in-one-figure",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Multiple Datasets in One Figure",
    "text": "Multiple Datasets in One Figure\n\n\n\nBasics\nExample\nHow can we make the legend?\n\n\n\nSo far, we have been using the same dataset for each layer of the plot. But you can use multiple datasets in a single plot.\n\nNote\n\nIf you specify data in ggplot() at the beginning (e.g., ggplot(data = dataset)), the data applies to ALL the subsequent geom_*()s unless overwritten locally inside individual geom_*()s.\nTo use multiple datasets in a single plot, you just need to specify what dataset to use locally inside individual geom_*()s.\n\n\n\n\n\n\ninsurance_southwest is a subset of the insurance data where region is southwest.\n\ninsurance_northeast is a subset of the insurance data where region is northeast.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nYou can do something like this:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec3.html#themes",
    "href": "Lec3.html#themes",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "ggplot2 Themes (Optional)",
    "text": "ggplot2 Themes (Optional)\n\nYou can change the theme of the plot.\n\nggplot2 ships several pre-made themes that you can apply to your plots. (e.g, theme_minimal(), theme_bw() (I use this often), theme_classic()). See this.\nggthemes package provides additional ggplot themes. See this for full list of available themes.\n\n\nTry it!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec3.html#theme-function",
    "href": "Lec3.html#theme-function",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "theme() Function (Optional)",
    "text": "theme() Function (Optional)\ntheme() function let you tweak the details of all non-data related components of a plot (e.g., font type in the plot, position of the legend and title, etc.). There are so many components you can modify with the theme() function. See this for full list of options.\nFor more information, see:\n\nChapter 17 Themes, ggplot2: Elegant Graphics for Data Analysis (3e)\n\n\nTry it!\nFor example, you can change the position of the title and legend with the following theme() options.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec3.html#save-the-plot",
    "href": "Lec3.html#save-the-plot",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Save the Plot",
    "text": "Save the Plot\n\n\nBasics\n\n\nTwo options + Use the ggsave() function from the ggplot2 package. + Use the “Export” button in the RStudio plot viewer.\n\n\n\n\nSyntax:\nggsave(filename, plot = plot_object)\n\n\nfilename: the name of the file (including path) to save the plot to. (e.g., filename = “Data/plot.png”)\n\nplot: the plot object to save.\n\nExample\nRun the following code on your RStudio. Make sure you are opening the RProject.\n\nlibrary(ggplot2)\nlibrary(rio)\n\ninsurance_url &lt;- \"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\"\ninsurance &lt;- import(insurance_url)\n\nggplot(data = insurance) +\n  geom_boxplot(aes(x = sex, y = charges, fill = region)) +\n  labs(\n    x = \"Sex\",\n    y = \"Medical costs\",\n    title = \"Distribution of individual medical mosts by sex and region\"\n  )\n\n# --- Sve plot --- #\nggsave(filename = \"Data/insurance.png\")\nggsave(filename = \"Data/insurance.pdf\")\nggsave(filename = \"Data/insurance2.png\", plot = plot_insurance)\n\n\n:::"
  },
  {
    "objectID": "Lec3.html#summary-2",
    "href": "Lec3.html#summary-2",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Summary 2",
    "text": "Summary 2\nFor this second section, you learned a few advanced topics in ggplot2.\nNow, you know;\n\nhow to create facet plots with facet_wrap() and facet_grid().\nwhen to use facet_wrap() and facet_grid().\nhow to visualize multiple datasets in a single plot.\nhow to save the plot.\n\nThat’s it!"
  },
  {
    "objectID": "Lec3.html#exercise-problems3",
    "href": "Lec3.html#exercise-problems3",
    "title": "Day 3: Data visualization with ggplot2 package",
    "section": "Exercise Problems",
    "text": "Exercise Problems\n\n\n\nExercise Problem 1 (basic)\nExercise Problem 2 (basic)\nExercise Problem 3 (challenging)\n\n\n\n\n\n\nData\nInstructions\nSolutions\n\n\n\nFor this exercise problem, you will use the gapminder data from the gapminder package.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nFind the number of unique countries in the data.\nCalculate the mean life expectancy for the entire dataset.\nCreate a dataset by subsetting the data for the year 2007. Create a scatter plot of GDP per capita vs. life expectancy for the year 2007, color-coded by continent.\nCreate a bar plot showing the total population for each continent in 2007. Fill the bars with blue and set the transparency to 0.5.\nSubset the data for the United States, China, India, and the United Kingdom. Create a line plot showing the change in life expectancy over time for these countries.\nCreate a scatter plot of GDP per capita vs. life expectancy for the entire gapminder dataset. Use facet_wrap to create separate plots for each continent.\nGroup the data by continent and calculate the mean GDP per capita for each continent for each year. Create a line plot showing the trend of mean GDP per capita for each continent over time.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\nData\nInstruction\nSolutions\n\n\n\nFor this exercise problem, we will use economics dataset from the ggplot2 package. You need to use data manipulation and visualization techniques using the data.table and ggplot2 packages.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nAs you already know by now, the economics dataset contains various economic indicators for the United States. We want to create a line plot showing the trends of all economic indicators over time. Each economic indicator is stored in a separate column in the data, and you can visualize each indicator by creating a single line plot, separately. But, there is a better way to do this. It should look like the following plot.\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\nInstruction\nSolutions\n\n\n\nFor this exercise problem, you will use “corn_yield_dt.rds” in the “Data” folder. I obtained this from USDA-NASS Quick Stats database. The data contains the county-level corn yield data (in BU / ACRE) for each major corn production state in the US Midwest from 2000 to 2022.\n\n\nLoad the data and take a look at it.\nConvert the data to a data.table object. The Value column contains the corn yield data. Rename the column to yield.\nLet’s derive the state-level annual average corn yield data by calculating the mean of corn yield by state and year. Create a line plot of the annual trend of corn yield in Minnesota by taking year for the x-axis and the derived mean yield for the y-axis.\nCreate line plots showing the trend of annual corn yield for each state in the same plot.\nCreate a facet plot showing each state’s annual corn yield trend. To compare the trends across states, use scales = \"fixed\".\n\nHint: state_alpha is the two-letter state abbreviation for each state.\n\nCreate a new dataset that contains the overall average corn yield across states by taking the mean of the yield by year. Add a line plot of this dataset to the plot you created in the previous step. Use red dashed line to represent this line.\n\n\nIf you could add a legend to the plot to indicate what the red dashed line means, that would be great! To do this, you need to use scale_color_manual() function.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec5.html#introduction",
    "href": "Lec5.html#introduction",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "Introduction",
    "text": "Introduction\n\nIn the previous lecture, we learned how to do regression analysis using R, which is a fundamental skill for econometric analysis.\nToday, we will learn how to code Monte Carlo simulations in R. Monte Carlo simulations are a very important tool in learning econometrics and statistics. With Monte Carlo simulations, you can test any kind of statistical theory or property, which is very useful!!\n\n\n\nNote\nBefore we start the Monte Carlo simulation, let’s review a few key R concepts:\n\nfor loop function: how they work and when to use them.\nWriting your own functions: we won’t need this for today’s simulation, but it’s an important skill to practice for future coding tasks."
  },
  {
    "objectID": "Lec5.html#section",
    "href": "Lec5.html#section",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "",
    "text": "Learning Objectives\n\nto be able to write code for your own R functions.\nto be able to write code for a Monte Carlo simulation using the loop function.\n\n\n\n\n Reference\n\nSection 19 Functions\n\nSection 20 Iteration in R for Data Science"
  },
  {
    "objectID": "Lec5.html#todays-outline",
    "href": "Lec5.html#todays-outline",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "\n Today’s Outline",
    "text": "Today’s Outline\n\nUser-Defined Functions\n\nLoops\n\nBasics\nHow to Save the Loop Output\nMultiple Outputs\n\n\n\nIntroduction to Monte Carlo Simulations\n\nDemonstration\n\n\nOverall Review"
  },
  {
    "objectID": "Lec5.html#fn",
    "href": "Lec5.html#fn",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "Introduction to User-Defined Functions",
    "text": "Introduction to User-Defined Functions\n\n\n\nIntro\nBasics\nExamples\nDefault Value\n\n\n\nYou can define your own functions. The beauty of creating your own functions is that you can reuse the same code over and over again without having to rewrite it. A function is more useful when the task is longer and more complicated.\n\nExample Situations\n\nWhen you want to automate the process of data cleaning.\nWhen you do a complicated simulation or resampling methods, such as bootstrapping or Monte Carlo simulations.\n\n\n\nYou can define your own functions using the function() function. \nGeneral Syntax\nfunction_name &lt;- function(arg1, arg2, ...){\n  code to be executed\n\n  return(output)\n}\n\nNote + You need to define the function name (function_name), what kind of inputs the function takes (arg1, arg2, etc.), and how the function processes using the given input objects. + The return() function is used to return the output of the function. By default, the output defined in the last line of the function is returned.\n\n\nfunction_name &lt;- function(arg1, arg2, ...){\n  code to be executed\n\n  return(output)\n}\n1. A simple function\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n2. A function with multiple outputs\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nYou can set default values for function arguments by argument = value.\n\nExample:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec5.html#load-functions-from-a-file",
    "href": "Lec5.html#load-functions-from-a-file",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "Load Functions from a File",
    "text": "Load Functions from a File\nIf you have multiple functions or a long function, you might want to save the function in a separate file and load it when you need it.\nFor example:\n\nSave the function code file in a .R file (.Rmd, etc.).\n\nClick File -&gt; Save As...\n\nChoose a name, e.g., my_function.R.\n\n\nLoad the function using the source() function.\n\nLet’s practice this on your Rstudio!"
  },
  {
    "objectID": "Lec5.html#fn-ex",
    "href": "Lec5.html#fn-ex",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "In-class Exercise",
    "text": "In-class Exercise\n\n\n\nExercise 1\nExercise 2 (optional)\n\n\n\n\nQuestions\n\n\n\nWrite a function (you can name it whatever you want) to calculate the area of a circle with a given radius. The function should return the area of the circle. (Hint1: Area = π × r^2; Hint2: Use pi, which is a built-in constant for the value of \\(\\pi\\) in R.)\nWrite a function to count the number of NA values in a given vector. (Hint: use the is.na() function.)\nWrite a function called mean_no_na that calculates the mean (average) of a numeric vector, but ignores any NA values.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nQuestions\n\n\nYou’re a data expert at a store chain. The company needs to study its monthly sales growth to plan better. They expect sales to grow by a fixed percentage each month. Your job is to create an R function that shows sales growth over a year.\nFor sales growth, use the following formula:\n\\[S_t = S_0 \\times (1 + g)^{t-1}\\]\n, where \\(S_t\\) is the sales in month \\(t\\) , \\(S_0\\) is the starting sales, and \\(g\\) is the growth rate.\nCreate a function called monthly_sales_growth with the following three inputs:\n\n\ninitial_sales: Starting sales (in thousands of dollars).\n\ngrowth_rate: Monthly growth rate (as a decimal, like 0.03 for 3% growth).\n\nmonths: How many months to predict (usually 12 for a year).\n\nThe function should give back a vector of numbers (or it would be even better if you could show in a data.frame or data.table in which two columns, e.g., month and sales, show the expected sales for each month.)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec5.html#why-loop",
    "href": "Lec5.html#why-loop",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "Why loop?",
    "text": "Why loop?\nUsing Loop is useful when you want to repeat the same task (but with a slight change in parameters) over and over again.\n\nExamples\n\nDownloading the data from the web iteratively.\n\nWhen you want to download the ag-production data from USDA-NASS, you are limited to download 50,000 records per query. You need to repeatedly download the data until you get all the data you need.\nUSDA crop scale data, NOAA weather data, etc.\n\n\nLoading multiple data files in a folder.\nRunning the same regression analysis for multiple datasets.\nRunning simulations or resampling methods, such as bootstrapping or Monte Carlo simulations.\n\n\n\nWhile there are several looping commands in R (e.g., foreach, lapply, etc.), we will use the for loop function, as it is the most basic and widely used looping function in R."
  },
  {
    "objectID": "Lec5.html#loops-basics",
    "href": "Lec5.html#loops-basics",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "For loops",
    "text": "For loops\n\n\n\nBasics\nExamples\n\n\n\nThe for loop function is a built-in R function. The syntax of the for loop is very simple. \nSyntax:\nfor (name in collection) {\n  # code to run for each element\n}\n\nComponents\n\n\nname (loop variable): a placeholder that takes on one value from the collection each time the loop runs.\n\n\ncollection: the set of values you want to loop over (usually a vector or list).\n\n\ncode block: the instructions you want R to execute at each step.\n\n\nNote\n\nOn each iteration, the loop variable (name) takes the next value from the collection.\n\nThe collection can be:\n\nA numeric sequence (e.g., 1:5)\n\nA character vector (e.g., c(\"apple\", \"banana\"))\n\nA list of objects (e.g., datasets)\n\n\n\n\n\n1. Print the numbers from 1 to 5.\nLoop variable i takes each number in the sequence 1:5 in order and print the value of i.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n2. Print characters in a list.\nLoop variable x takes each character in the list list(\"I\", \"like\", \"cats\") in order and print the value of x.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n3. Calculate the mean of each element in a list.\nCan you tell me what’s going on in the following code?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nls_seq_num is a list of three vectors, and each vector is a sequence of values.\nAs I said before, variable seq_num takes each vector in the collection of objects ls_seq_num in order."
  },
  {
    "objectID": "Lec5.html#loops-basics-ex",
    "href": "Lec5.html#loops-basics-ex",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "In-class Exercise",
    "text": "In-class Exercise\n\n\n\nExercise 1\nExercise 2 (nested loop)\n\n\n\n\nQuestions\n\n\nIn econometric class, we use the rnorm() function a lot! It is a function that generates random numbers from a normal distribution. See ?rnorm for more details.\nThe basic syntax is rnorm(n, mean = 0, sd = 1), where n is the number of random numbers you want to generate, mean is the mean of the normal distribution, and sd is the standard deviation of the normal distribution. So rnorm(n, mean =0, sd = 1) generates n random numbers from a standard normal distribution.\n\nGenerate 1000 random numbers from a standard normal distribution and calculate the mean the numbers (use mean() function), and print the results. Repeat this process 10 times using the for loop.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nQuestions\n\n\nYou can nest the for loop inside another for loop. For example,\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nUsing the above code as a reference, fill in the following empty 3 x 3 matrix with the sum of the row and column indices.\nThe output should look like this:\n\n\n     [,1] [,2] [,3]\n[1,]    2    3    4\n[2,]    3    4    5\n[3,]    4    5    6\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec5.html#loops-save",
    "href": "Lec5.html#loops-save",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "For loops: How to Save the loop output?",
    "text": "For loops: How to Save the loop output?\n\n\n\nIntroduction\nBasics\n\n\n\nUnlike R functions we have seen so far, for loop does not have a return value. It just iterates the process we defined in the loop.\n\nLet’s do some experiments:\n\n\n\nExperiment 1\nExperiment 2\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nEvery round of the loop, the variables defined inside the loop are updated.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nYou cannot assign loop to a variable directly (e.g x &lt;- for (i in 1:3){print(i)} does not work).\n\n\n\n\n\n\n\n\n\nTo save the results of the loop, you need to create an empty object before the loop and save the output in the object in each iteration. (You did this in the exercise 2!)\n\nThe object can be a vector, a list, a matrix, or a data frame (or data.table), depending on the type of the output you want to save.\n\n\n\nExample\nSuppose you want to cube each number in the sequence 1:5.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNote\n\nSince the output of each iteration is a number, vector is a good choice for the storage object. (Alternatively you can use a list object.)"
  },
  {
    "objectID": "Lec5.html#loops-multi",
    "href": "Lec5.html#loops-multi",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "Multiple Outputs",
    "text": "Multiple Outputs\nWhat if we want to have multiple outputs from the loop and combine them into a single dataset?\nExample\nLet’s generate 100 random numbers from a standard normal distribution and calculate the mean and the standard deviation of numbers. Repeat this process 10 times using the for loop and save the results in a dataset.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec5.html#loops-save-ex",
    "href": "Lec5.html#loops-save-ex",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "In-class Exercise",
    "text": "In-class Exercise\n\n\n\nExercise 1\nExercise 2 (optional)\n\n\n\n\nQuestions\n\n\n\nUsing the for loop, calculate the sum of the first n numbers for n = 1, 2, ..., 10. For example, the sum of the first 3 numbers (n=3) is 1 + 2 + 3 = 6. Save the results in a vector object.\nFibonacci sequence is a series of numbers in which each number is the sum of the two preceding ones (e.g. 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, …). Write a function that generates the first n numbers in the Fibonacci sequence. (You use the for loop function inside the function.) For example, when n = 5, the function should return c(0, 1, 1, 2, 3). For simplicity, let’s assume that \\(n \\ge 3\\) (You don’t need to consider the case where n = 1 or 2).\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nQuestions\n\n\nNOTE: It’s okay if you cannot solve this problem! I will show two approaches to solve this problem, and do speed comparison between the two approaches.\nPythagorean triples are sets of three positive integers \\((a, b, c)\\) that satisfy the equation \\(a^2 + b^2 = c^2\\), who are named after the ancient Greek mathematician Pythagoras.\nLet’s take this concept further. Suppose Pythagoras challenges you to find all possible Pythagorean triples where \\(a\\) and \\(b\\) are less than or equal to a given number \\(n\\). To address this problem, let’s create an R function that will produce all such triples.\n\nWrite a function that takes one argument n, an integer, representing the maximum value for a and b. The function should return a data frame with columns a, b, and c, containing all Pythagorean triples where \\(b \\leq a \\leq n\\) and \\(a^2 + b^2 = c^2\\).\n\n\n\n\nHints:\n\n\n\nConsider using nested loops to iterate through all possible values of a and b up to n.\nUse the sqrt() function to calculate the potential value of c, and check if it’s an integer.\nUse the floor() function to round down the value of c.\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nReference: Pythagorean Triples"
  },
  {
    "objectID": "Lec5.html#check-point",
    "href": "Lec5.html#check-point",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "Check Point",
    "text": "Check Point\n\nUp to this point, as long as you understand the following points, you are good to go!\n\nYou know how to use function() to define a simple function yourself.\nYou know how to use for loop (i.e., syntax, which argument you need to define).\nYou know that you need to prepare an empty object to save the output of the loop."
  },
  {
    "objectID": "Lec5.html#introduction-to-monte-carlo-simulations",
    "href": "Lec5.html#introduction-to-monte-carlo-simulations",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "Introduction to Monte Carlo Simulations",
    "text": "Introduction to Monte Carlo Simulations\n\n\nAnalogy\nWhat is it?\nMonte Carlo simulation in Econometrics\n\n\n\n\nImagine you want to know the chance of winning a dice game. Instead of trying to calculate the exact probability with formulas, you could just roll the dice thousands of times, record the outcomes, and then see how often you win.\nThat’s basically what Monte Carlo Simulation does: it uses repeated random experiments to approximate answers to problems that are hard to solve analytically.”\n\nKey ideas:\n\nWe model uncertainty with randomness.\n\nWe simulate many scenarios (sometimes thousands or millions).\n\nWe average the results to estimate probabilities, risks, or outcomes.\n\n\n\n\n\nMonte Carlo simulation is a technique to approximate a likelihood of possible outcomes (e.g., predictions, estimates) from a model by iteratively running the model on artificially created datasets. In every iteration, the datasets are randomly sampled from the assumed data generating process, so it varies every iteration.\n\nThe incorporation of randomness in the simulation is the key feature of the Monte Carlo simulation. It is mimicking the randomness of real-world phenomena.\n\n\n\n\n\nIn econometrics, the Monte Carlo simulation is used to evaluate the performance of a statistical procedure or the validity of theories in a realistic setting.\nFor example\nSuppose that a researcher came up with a new estimator to estimate the coefficients of a regression model.\n\nAn estimator (e.g, sample mean, standard error, OLS) is a function of a random variable, therefore it is also a random variable.\nA random variable has its own probability distribution.\nSo, to understand the performance of the estimator (e.g., unbiasedness and efficiency), we need to examine the properties of the probability distribution of the estimator.\nWe use Monte Carlo simulation to approximate the probability distribution of the estimator!"
  },
  {
    "objectID": "Lec5.html#monte-demo",
    "href": "Lec5.html#monte-demo",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "Example: Binomial Distribution",
    "text": "Example: Binomial Distribution\nThink about the following example.\nExample\n\nSuppose that we flip a coin \\(n=10\\) times and count the number of heads. Let’s denote the number of heads \\(X\\).\nThe coin is not fair, however. The probability of getting a head is \\(p= Pr[heads] = 1/3\\).\nSuppose that you repeat this experiment \\(1000\\) times. What is the mean and the variance of \\(X\\)?\n\n\n\nThis kind of experiment is modeled by the binomial distribution. According to the theory, it is predicted that\n\nMean of \\(X\\) is \\(E[X] = np = 10 \\times 1/3 = 3.33\\)\n\nVariance of \\(X\\) is \\(Var[X] = np(1-p) = 10 \\times 1/3 \\times 2/3 = 2.22\\)\n\n\n\n\n\nIs it true? Let’s check this using a Monte Carlo simulation!"
  },
  {
    "objectID": "Lec5.html#section-1",
    "href": "Lec5.html#section-1",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "",
    "text": "Monte Carlo Simulation: Steps\n\nstep 1: Specify the data generating process.\n\nYou need to pick a specific probability distribution to generate a random number.\n\nstep 2: Repeat:\n\nstep 2.1: generate a (pseudo) random sample data based on the data generating process.\nstep 2.2: get an outcome you are interested in based on the generated data.\n\nstep 3: compare your estimates with the true parameter"
  },
  {
    "objectID": "Lec5.html#demonstration-binomial-distribution",
    "href": "Lec5.html#demonstration-binomial-distribution",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "Demonstration: Binomial Distribution",
    "text": "Demonstration: Binomial Distribution\n\n\n\nA Single Iteration\nMultiple Iterations\n\n\n\nLet’s start writing code for a single iteration to get an idea of the Monte Carlo simulation process in R.\n\nWe want to repeat this 1000 times.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec5.html#exercise-problem-weak-low-of-large-number",
    "href": "Lec5.html#exercise-problem-weak-low-of-large-number",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "Exercise Problem: (Weak) Low of Large Number",
    "text": "Exercise Problem: (Weak) Low of Large Number\n\n\nQuestions\n\n\nWeak law of large number states that the sample mean converges (in probability) to the population mean as the sample size increases. In other words, the sample mean more accurately estimates the population mean as the sample size increases.\n\\[\\bar{X}_n = \\frac{1}{n}\\sum_{n=1}^{n} X_i E[X] \\xrightarrow{p} E[X]\\]\nLets check this using Monte Carlo simulation! We compare the distribution of sample mean with different sample size. Let’s compare two sample sizes: \\(n=100\\) and \\(n=1000\\).\n\nProcess\nRepeat 1 and 2 for \\(B=1000\\) times.\n\nUsing a normal distribution with mean \\(\\mu = 5\\) and \\(sd = 10\\), generate random numbers for \\(n=100\\) and \\(n=1000\\). e.g. rnorm(n = 10, mean = 5, sd = 10).\nCompute sample mean for each sample data, and save them.\n\nFinally,\n\nPlot histograms of the sample means obtained from the two samples."
  },
  {
    "objectID": "Lec5.html#exercise-problem-two-estimators-to-estimate-the-population-mean-optional",
    "href": "Lec5.html#exercise-problem-two-estimators-to-estimate-the-population-mean-optional",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "Exercise Problem: Two estimators to estimate the population mean? (optional)",
    "text": "Exercise Problem: Two estimators to estimate the population mean? (optional)\n\n\n\nQuestions\nHint\n\n\n\nSuppose you’re interested in estimating the unknown population mean of men’s heights (i.e., \\(\\mu\\)) in the US. We have randomly sampled data with the size of \\(n=1000\\). Let \\(X_i\\) denote the individual \\(i\\)’s height in the sample. How should we use the sample data to estimate the population mean?\n\nYour friends suggested two different estimators:\nEstimator 1. Use the sample mean: \\(\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i\\)\nEstimator 2. Use only the first observation: \\(X_1\\)\n\n\nTheoretically, both estimators are unbiased estimators (i.e., if we repeat the estimation process many times on a different sample data every time, the average of the estimates will be equal to the population mean):\n\n\\[\\begin{align*}\nE[\\bar{X}_n] &= E \\left[\\frac{1}{n} \\sum_{i=1}^{n} \\right] = \\frac{1}{n} E \\left[\\sum_{i=1}^{n} X_i \\right] = \\frac{1}{n} \\sum_{i=1}^{n} E[X_i] = \\frac{1}{n} \\cdot n \\cdot \\mu = \\mu \\\\\nE[X_1] &= \\mu\n\\end{align*}\\]\n\n\n\n\n\nQuestions:\n\n\n\nIs it true that both estimators are correctly estimating the population mean, on average?\nWhich one is more accurate in estimating the population mean?\n\nUsing Monte Carlo simulation, let’s examine these questions!\n\n\n\n\n\n\n\nRepeat the following processes 1000 times:\n\nstep 1. Draw \\(n = 1000\\) random numbers with known mean \\(\\mu\\) and standard deviation \\(\\sigma\\). This will be the sample data.\nstep 2. Get (1) the mean of the sample and (2) the value of the first observation, and save the results.\n\nThe previous iterations produce 1000 estimates of the population mean for estimator 1 and estimator 2, respectively. Compute the means for each estimator. Are they both close to the true population mean? Compute the variance of the estimates. Which one has a smaller variance?\n\nIf you could also visually compare the distribution of estimates from the two estimators, that would be great!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec5.html#foreach-function",
    "href": "Lec5.html#foreach-function",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "\nforeach Function",
    "text": "foreach Function\n\n\n\nBasics\nExample\nChange the Output Format\n\n\n\nThe foreach function is a function of the foreach package. It is used to iterate the same process over and over again, similar to the for loop function.\n\nBasic Syntax\nWhile there are some differences, the basic syntax of the foreach function is pretty much similar to the for loop function.\nforeach(variable = collection_of_objects) %do% {\n  the code to be executed in each iteration\n\n  return(output)\n}\n\nNote\n\nDifferences between for loop and foreach function:\n\nuse = instead of in.\nYou need to use %do% operator.\n\nforeach function has a return value, while for loop does not. By default, the output is returned as a list.\n\n\n\nforeach function also supports parallel processing. (we will not cover this in this class.)\n\n\n\n\nUsing the for loop and foreach function, let’s calculate the square of the numbers from 1 to 10, respectively.\n\n\nforeach\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nfor loop\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nBy default, foreach function returns each iteration’s result as a list. But you can choose the format of the output by using the .combine argument.\n\n\n.combine = c combines each iteration’s result as as a vector (like c() to create a vector).\n\n.combine = rbind combines each iteration’s result by row.\n\n.combine = cbind combines each iteration’s result by column.\n\nThe last two options are used when the output is a matrix or a data.frame (or data.table).\n\nExample\n\nTry different .combine options in the following code.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec5.html#review",
    "href": "Lec5.html#review",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "Review",
    "text": "Review\n\n\nBasics of R\nData Manipulation with data.table\nVisualization with ggplot2\nRegression & Reporting\nFunctions, Loops, & Monte Carlo\n\n\n\n\nCoding rules & projects: file paths, working directories, using .Rproj.\nData types: numeric, character, logical; handling NA.\nCore structures: vectors, matrices, data frames — creation, indexing, subsetting.\nBase math & objects: assignment, arithmetic, functions; saving/loading data.\n\n\n\n\nDT[i, j, by] pattern and chaining.\nRow filtering and column selection; create/modify columns with :=.\nGrouped summaries with by; ordering and efficient aggregation.\nReshaping with melt() and dcast() (wide ↔︎ long).\n\n\n\n\nGrammar of Graphics: data + aes() + geom_*.\nCommon plots: scatter, line, bar, histogram, box, density; faceting.\nAesthetics: color/size/shape, grouping, collective geoms.\nLabels/themes: axes, titles, legends; layering multiple datasets.\n\n\n\n\nLinear models with lm().\nmodelsummary for publish-ready regression tables; datasummary for descriptives.\nCustomization: model labels, stats formatting, notes.\nQuarto reporting: render to HTML/PDF for reproducible outputs.\n\n\n\n\nUser-defined functions function(): arguments, returns, defaults; save in .R and source().\nLoops function for(): basics, saving outputs, multiple outputs.\nRandomness & reproducibility: set.seed(), rnorm(), sample(..., replace=TRUE)."
  },
  {
    "objectID": "Lec5.html#review-exercise",
    "href": "Lec5.html#review-exercise",
    "title": "Day 5: Function, Loops, and Monte Carlo Simulations",
    "section": "Review Exercise",
    "text": "Review Exercise\n\n\nInstructions\nQuestions\n\n\n\nThis exercise integrates all major concepts from our R course. We will use the built-in R datasets mtcars provided.\nSetup (Run this first!)\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nData Structures and Basic Operations\ndata.table Operations\nData Visualization\nRegression Analysis\nProgramming\n\n\n\n\nShow the structure of mtcars_dt\nCalculate the mean mpg (miles per gallon) for all cars\nCreate a logical vector showing which cars have both mpg &gt; 20 AND hp &lt; 150\nExtract the car names of cars with the highest mpg\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nCreate a new column ‘power_ratio’ = hp/wt (horsepower per weight) and add it to mtcars_dt\nReplace all mpg values less than 15 with NA\nFilter mtcars_dt to show only cars with automatic transmission (am == 0)\nSort mtcars_dt by mpg in descending order and show top 5 cars\nCalculate average mpg by number of cylinders (cyl)\nFor each transmission type (am), calculate: count of cars, mean mpg, mean hp\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nCreate a scatter plot of wt vs mpg, with:\n\nDifferent colors for transmission type (am).\nDifferent shapes for number of cylinders (cyl).\nA smooth trend line for each transmission type.\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nRun a regression: mpg ~ hp + wt + factor(cyl)\nExtract the coefficient for hp from your model\nRun a second model: mpg ~ hp + wt + factor(am), and create a comparison table using modelsummary() for both models\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nWrite a function that calculates mpg per cylinder (mpg/cyl)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nUse a for loop to calculate the mean mpg for cars with 4, 6, and 8 cylinders. Store results in a vector called ‘cyl_means’\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec4.html#recap",
    "href": "Lec4.html#recap",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "Recap",
    "text": "Recap\n\nSo far, we have learned…\n\nThe basic types of data structures in R, and how to create and manipulate them.\nData wrangling with data.table package.\nData visualization with ggplot2 package.\n\nWith the tools we learned so far, you can do a lot of tasks for descriptive data analysis!\nOnce you have a good understanding of the data, you can move on to the next step: econometric analysis!"
  },
  {
    "objectID": "Lec4.html#section",
    "href": "Lec4.html#section",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "",
    "text": "Learning Objectives\nToday’s goal is to:\n\ncreate a descriptive summary table for the data.\nuse lm function to estimate a regression model and report the results with publication-ready summary tables.\nunderstand how to create a report document (html and PDF) with Quarto.\n\n\n\n\n Reference\n\n\nmodelsummary package [See here for the package documentation, important!]"
  },
  {
    "objectID": "Lec4.html#notes",
    "href": "Lec4.html#notes",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "Notes",
    "text": "Notes\n\n\nToday’s lecture is an introduction to basic regression analysis with R.\n\nThe more advanced R functions such as feols() function from fixest package for fixed effects models and glm() function for generalized linear models will be covered in the Econometric class (APEC 8211-8214).\n\nBut the basic syntax are the same. So, you can easily apply the knowledge you learn today to the more advanced functions."
  },
  {
    "objectID": "Lec4.html#todays-outline",
    "href": "Lec4.html#todays-outline",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "Today’s outline:",
    "text": "Today’s outline:\n\nIntroduction to Regression analysis with R\n\nCreate a summary table\n\nIntroduction to modelsummary package\nmodelsummary() function to report regression results\nmodelsummary() function: Customization\ndatasummary() function to report descriptive statistics"
  },
  {
    "objectID": "Lec4.html#before-we-start",
    "href": "Lec4.html#before-we-start",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "Before We Start",
    "text": "Before We Start\nWe will use the CPS1988 dataset from the AER package. It’s a cross-section dataset originating from the March 1988 Current Population Survey by the US Census Bureau. For further information, see ?CPS1988 after loading the package.\nRun the following code:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec4.html#introduction-to-regression-analysis-with-r-1",
    "href": "Lec4.html#introduction-to-regression-analysis-with-r-1",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "Introduction to Regression Analysis with R",
    "text": "Introduction to Regression Analysis with R\n\n\n\nBasics of lm()\nExample\nSummary Results\nExtracting Information1\nExtracting Information2\nIn-class Exercise\n\n\n\nThe most basic function to estimate a linear regression model in R is the lm function from stats package, which is a built-in R package.\n\nSuppose we have a regression model of the form: \\[Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + e\\]\n\nWith the lm function, we can estimate the above model as follows:\n\n# Example R-code\nlm(formula = Y ~ X1 + X2, data = dataset)\n\n\n\nIn the first argument of the lm function, you specify the formula of the regression model.\nThe intercept is included by default. So, you don’t need to include it in the formula.\n\n~ splits the left side and right side in a formula.\n\n\n\nLet’s estimate the following model with the CPS1988 data:\n\\[wage = \\beta_0 + \\beta_1 education + \\beta_2 experience + e\\]\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nThe output looks so simple.\nBut the the output of lm function contains a lot of information other than the estimated coefficients.\nSee names() (or ls()). Or you can see the information stored in the\n\n\n\nTo see the summary of the regression results, use the summary function.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThe results from lm() and summary() contain a lot of information (In your Rstudio, you can check them on the Environment pane).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nYou can access any information stored in object via the $ operator.\n\n\nExample 1: Extract the fitted values\nExample 2: The coefficient estimates\nExample 3: The coefficient estimates with standard errors and t-statistics.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nContents of lm() vs summary(lm()) objects.\n\n\n\n\n\n\n\n\n\nCategory\nIn lm() object (reg)\nIn summary(lm()) object (reg_summary)\n\n\n\nCoefficients\n\ncoefficients: estimated β-hats\n\ncoefficients: table of β-hat, Std. Error, t, p\n\n\nResiduals\n\nresiduals: raw residuals\n\nresiduals: residuals (trimmed for summary)\n\n\nFitted Values\n\nfitted.values: predicted ŷ\n–\n\n\nModel Info\n\ncall, terms, model, assign, xlevels\n\n\ncall, terms, plus degrees of freedom info\n\n\nDiagnostics\n–\n\nr.squared, adj.r.squared, sigma, fstatistic\n\n\n\nVariance–Covariance\n\nqr, effects, rank, df.residual\n\n\ncov.unscaled, aliased\n\n\n\nDegrees of Freedom\ndf.residual\n\ndf: regression, residual, total\n\n\n\n\n\n\n\nQuestions\nAnswers\n\n\n\nLet’s get the value of the standard error of the coefficient estimate of education.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nLet’s get the value of the standard error of the coefficient estimate of education.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec4.html#regression-with-various-functional-forms",
    "href": "Lec4.html#regression-with-various-functional-forms",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "Regression with Various Functional Forms",
    "text": "Regression with Various Functional Forms\n\nBasics\n\nTo include interaction terms in the formula in lm() function:\n\n\n* = main effects + interactions.\n\n\n: = interaction only.\n\n\nTo include arithmetic terms in the formula in lm() function, use the I() function.\n\n\nI() = arithmetic (square, product, etc).\n\n\nFor log transformation, use the log() function in the formula.\n\nOr you define a new variable with the transformed variable and include it in the formula.\n\n\n\nExample:\nTo estimate: \\[log(wage) = \\beta_0 + \\beta_1 education + \\beta_2 experience + \\beta3 experience ^2 + e\\]\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec4.html#categorical-variables",
    "href": "Lec4.html#categorical-variables",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "Categorical Variables",
    "text": "Categorical Variables\n\n\n\nBasics\nExamples\nSet the Base Group\n\n\n\nWhat if we want to include a categorical variable (e.g., region, parttime, ethnicity) in the regression model?\nlm() function is smart enough to convert the categorical variable into dummy variables without any additional coding.\n\nEven the variables you want to use as dummy variables are character type, lm() function automatically coerced it into a factor variable.\n\n\n\n\n\n\nTwo categories\nMore than Two Categories\n\n\n\nWhat if we want to include a dummy variable that takes 1 if parttime is yes, otherwise 0?\nThe model is as follows: \\[\nlog(wage) = \\beta_0  + \\beta_1 education + \\beta_2 experience + \\beta_3 experience^2 + \\beta_4 d_{parttime, yes} + e\n\\]\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nWhat if we want to include dummy variables for each region?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nBy default, R picks the first group in the alphabetical order for the base group.\nYou can use relevel() function (a built-in R function) to set the base group of the categorical variable.\nSyntax:\n\nrelevel(factor_variable, ref = \"base_group\")\n\n\nExample:\nLet’s compare the two regression results:\n\nuse parttime==no as the base group\nuse parttime==yes as the base group\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec4.html#prediction",
    "href": "Lec4.html#prediction",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "Prediction",
    "text": "Prediction\nTo do prediction with the estimated model on a new dataset, you can use the predict function (built-in R function).\nSyntax\n\npredict(lm_object, newdata = new_dataset)\n\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec4.html#key-points",
    "href": "Lec4.html#key-points",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "Key Points",
    "text": "Key Points\n\nYou should at least know these key points:\n\nthe basic usage of lm() and summary() function.\nhow to retrieve the information stored in the outputs of lm() and summary() functions.\nhow to include log-transformed variable, interaction terms and quadratic terms in the formula of lm() function.\nhow to include categorical variables in the formula of lm() function, and how to set the base group.\nhow to do prediction with the estimated model on a new dataset.\n\nThat’s it!"
  },
  {
    "objectID": "Lec4.html#modelsummary-package-introduction",
    "href": "Lec4.html#modelsummary-package-introduction",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "Introduction to modelsummary package",
    "text": "Introduction to modelsummary package\n\n\nIntro\nExample\n\n\n\nmodelsummary package lets you create a nice summary table to report the descriptive statistics of the data and the regression results.\nWe focus on two functions in the modelsummary package:\n\n\ndatasummary(): to create a summary table for the descriptive statistics of the data.\n\nmodelsummary(): to create a summary table for the regression results.\n\nCheck the documentation for more details.\n\n\n\n\nDescriptive Statistics\n\n\n\nTable 1: Example of Summary Statistics\n\n\n\n\n\n\n\nMean\nSD\nMin\nMax\n\n\n\nWage\n603.73\n453.55\n50.05\n18777.20\n\n\nEducation\n13.07\n2.90\n0.00\n18.00\n\n\nExperience\n18.20\n13.08\n-4.00\n63.00\n\n\n\n\n\n\n\n\n\n\nRegression Summary Table\n\n\n\nTable 2: Example regression results\n\n\n\n\n\n\n\nOLS 1\nOLS 2\nOLS 3\n\n\n\nEducation\n0.076***\n0.087***\n0.086***\n\n\n\n(0.001)\n(0.001)\n(0.001)\n\n\nExperience\n\n0.078***\n0.077***\n\n\n\n\n(0.001)\n(0.001)\n\n\nExperience squared\n\n-0.001***\n-0.001***\n\n\n\n\n(0.000)\n(0.000)\n\n\nWhite\n\n\n-0.243***\n\n\n\n\n\n(0.013)\n\n\nNum.Obs.\n28155\n28155\n28155\n\n\nR2\n0.095\n0.326\n0.335\n\n\nR2 Adj.\n0.095\n0.326\n0.335\n\n\n\n\n* p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\nStd. Errors in parentheses"
  },
  {
    "objectID": "Lec4.html#modelsummary-function-introduction",
    "href": "Lec4.html#modelsummary-function-introduction",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "modelsummary() function to report regression results",
    "text": "modelsummary() function to report regression results\n\n\n\nBasics\nDefault Appearance\n\n\n\nThe very basic argument of the modelsummary() function is the models argument, which takes a list of regression models you want to report in the table.\n# --- 1. Estimate regression models --- #\nlm1 &lt;- lm(y ~ x1, data = dataset)\nlm2 &lt;- lm(y ~ x1 + x2, data = dataset)\nlm3 &lt;- lm(y ~ x1 + x2 + x3, data = dataset)\n\n# --- 2. Then, provide those a list of lm objects in the \"models\" argument  --- #\nmodelsummary(models=list(lm1, lm2, lm3))\n\n\n\n\nExample\n\nreg1 &lt;- lm(log(wage) ~ education, data = CPS1988)\nreg2 &lt;- lm(log(wage) ~ education + experience + I(experience^2), data = CPS1988)\n\nmodelsummary(models=list(reg1, reg2))\n\n\n\n\n\n\n\n\n\n(1)\n(2)\n\n\n\n(Intercept)\n5.178\n4.278\n\n\n\n(0.019)\n(0.019)\n\n\neducation\n0.076\n0.087\n\n\n\n(0.001)\n(0.001)\n\n\nexperience\n\n0.078\n\n\n\n\n(0.001)\n\n\nI(experience^2)\n\n-0.001\n\n\n\n\n(0.000)\n\n\nNum.Obs.\n28155\n28155\n\n\nR2\n0.095\n0.326\n\n\nR2 Adj.\n0.095\n0.326\n\n\nAIC\n405753.0\n397432.7\n\n\nBIC\n405777.7\n397473.9\n\n\nLog.Lik.\n-29139.853\n-24977.715\n\n\nF\n2941.787\n4545.929\n\n\nRMSE\n0.68\n0.59"
  },
  {
    "objectID": "Lec4.html#modelsummary-function-customization",
    "href": "Lec4.html#modelsummary-function-customization",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "modelsummary() function: Customization",
    "text": "modelsummary() function: Customization\n\n\nList of Options\nmodels\ncoef_map\nstars\nvcov\ncoef_omit\ngof_map and gof_omit\nothers\n\n\n\nThe default table is okay. But you can customize the appearance of the table. Here, I listed the bare minimum of options you might want to know (There are lots of other options!).\n\n\nmodels: you can change the name of the models\n\ncoef_map: to reorder coefficient rows and change their labels\n\nstars: to change the significance stars\n\nvcov: to replace the standard errors with the robust ones (we will see this later)\n\ngof_map: to define which model statistics to display\n\ngof_omit: to define which model statistics to omit from the default selection of model statistics\n\nnotes: to add notes at the bottom of the table\n\nfmt: change the format of numbers\n\n\nNote\n+ See ?modelsummary for more details or see this. + Also check the vignette of the function from here.\n\n\nBy naming the models when you make a list of regression models, you can change the name of the models in the table.\nExample\n\n\n\nreg1 &lt;- lm(log(wage) ~ education, data = CPS1988)\nreg2 &lt;- lm(log(wage) ~ education + experience + I(experience^2), data = CPS1988)\n\nls_regs &lt;- list(\"OLS 1\" = reg1, \"OLS 2\" = reg2)\n\nmodelsummary(models = ls_regs)\n\n\n\n\n\n\n\n\n\nOLS 1\nOLS 2\n\n\n\n(Intercept)\n5.178\n4.278\n\n\n\n(0.019)\n(0.019)\n\n\neducation\n0.076\n0.087\n\n\n\n(0.001)\n(0.001)\n\n\nexperience\n\n0.078\n\n\n\n\n(0.001)\n\n\nI(experience^2)\n\n-0.001\n\n\n\n\n(0.000)\n\n\nNum.Obs.\n28155\n28155\n\n\nR2\n0.095\n0.326\n\n\nR2 Adj.\n0.095\n0.326\n\n\nAIC\n405753.0\n397432.7\n\n\nBIC\n405777.7\n397473.9\n\n\nLog.Lik.\n-29139.853\n-24977.715\n\n\nF\n2941.787\n4545.929\n\n\nRMSE\n0.68\n0.59\n\n\n\n\n\n\n\n\n\n\n\ncoef_map argument helps you clean up your regression table.\n\nYou can choose which coefficients to show (subset).\nYou can change their order (reorder).\nYou can give them nicer labels (rename).\nIf you give a named vector, the names you supply will replace the default variable names in the table.\n\n\n\n\nExample\nIn this example, I renamed the variables and moved the intercept row to the bottom row.\n\n\n\nmodelsummary(\n  models =  list(\"OLS 1\" = reg1, \"OLS 2\" = reg2),\n  coef_map = c(\n    \"education\" = \"Education\", \n    \"experience\" = \"Experience\", \n    \"I(experience^2)\" = \"Experience squared\",\n    \"(Intercept)\" = \"Intercept\"\n    )\n  )\n\n\n\n\n\n\n\n\n\nOLS 1\nOLS 2\n\n\n\nEducation\n0.076\n0.087\n\n\n\n(0.001)\n(0.001)\n\n\nExperience\n\n0.078\n\n\n\n\n(0.001)\n\n\nExperience squared\n\n-0.001\n\n\n\n\n(0.000)\n\n\nIntercept\n5.178\n4.278\n\n\n\n(0.019)\n(0.019)\n\n\nNum.Obs.\n28155\n28155\n\n\nR2\n0.095\n0.326\n\n\nR2 Adj.\n0.095\n0.326\n\n\nAIC\n405753.0\n397432.7\n\n\nBIC\n405777.7\n397473.9\n\n\nLog.Lik.\n-29139.853\n-24977.715\n\n\nF\n2941.787\n4545.929\n\n\nRMSE\n0.68\n0.59\n\n\n\n\n\n\n\n\n\nstars = TRUE shows the significance stars in the table (Try it!).\nIf you don’t like it, you can modify significance levels and markers by specifying a named numeric vector (e.g., stars  =  c(\"*\" = .05, \"**\" = .01, \"***\" = .001)).\nExample\n\n\n\nmodelsummary(\n  models = list(\"OLS 1\" = reg1, \"OLS 2\" = reg2),\n  coef_map = c(\n    \"education\" = \"Education\", \n    \"experience\" = \"Experience\", \n    \"I(experience^2)\" = \"Experience squared\",\n    \"(Intercept)\" = \"Intercept\"\n    ),\n  stars  =  c(\"*\" = .05, \"**\" = .01, \"***\" = .001), \n  )\n\n\n\n\n\n\n\n\n\nOLS 1\nOLS 2\n\n\n\nEducation\n0.076***\n0.087***\n\n\n\n(0.001)\n(0.001)\n\n\nExperience\n\n0.078***\n\n\n\n\n(0.001)\n\n\nExperience squared\n\n-0.001***\n\n\n\n\n(0.000)\n\n\nIntercept\n5.178***\n4.278***\n\n\n\n(0.019)\n(0.019)\n\n\nNum.Obs.\n28155\n28155\n\n\nR2\n0.095\n0.326\n\n\nR2 Adj.\n0.095\n0.326\n\n\nAIC\n405753.0\n397432.7\n\n\nBIC\n405777.7\n397473.9\n\n\nLog.Lik.\n-29139.853\n-24977.715\n\n\nF\n2941.787\n4545.929\n\n\nRMSE\n0.68\n0.59\n\n\n\n* p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n\nBasics\nPreparation\nReport robust-standard errors\n\n\n\nvcov argument let you replace the non-robust standard errors (default) with the robust one. Here are some options to use the vcov argument (see this more options).\n\n\n\nOption 1: Supply a list of named variance-covariance matrices:\nvcov_reg1 &lt;- vcovHC(reg1, type = \"HC1\")\nvcov_reg2 &lt;- vcovHC(reg2, type = \"HC1\")\n\nmodelsummary(\n  models = list(\"OLS 1\" = reg1, \"OLS 2\" = reg2), \n  vcov = list(vcov_reg1, vcov_reg2)\n  )\n\nOption 2: Supply a name or a list of names of variance-covariance estimators (e.g, “HC0”, “HC1”, “HC2”, “HC3”, “HAC”).\nmodelsummary(\n  models = list(\"OLS 1\" = reg1, \"OLS 2\" = reg2), \n  vcov = \"HC1\"\n  )\nIn this case, HC1 estimator is used for all the models.\n\n\nNote\nBy default, modelsummary() calculates the robust variance-covariance matrix using the sandwich package (sandwich::vcovHC, sandwich::vcovCL).\n\n\nFirst, let’s get the heteroscedasticity robust variance-covariance matrix for the regression models.\n\nreg3 &lt;- lm(log(wage) ~ parttime + ethnicity, data = CPS1988)\nreg4 &lt;- lm(log(wage) ~ parttime, data = CPS1988)\n\n# Heteroscedasticity Robust standard errors\nlibrary(sandwich)\nvcov_reg3 &lt;- vcovHC(reg3, type = \"HC1\")\nvcov_reg4 &lt;- vcovHC(reg4, type = \"HC1\")\n\n\n\n\n\nBefore\n\nmodelsummary(\n  models = list(\"OLS 1\" = reg3, \"OLS 2\" = reg4),\n  stars  =  c(\"*\" = .05, \"**\" = .01, \"***\" = .001)\n  )\n\n\n\n\n\n\n\n\nOLS 1\nOLS 2\n\n\n\n(Intercept)\n6.009***\n6.274***\n\n\n\n(0.013)\n(0.004)\n\n\nparttimeyes\n-1.152***\n-1.157***\n\n\n\n(0.013)\n(0.013)\n\n\nethnicitycauc\n0.287***\n\n\n\n\n(0.014)\n\n\n\nNum.Obs.\n28155\n28155\n\n\nR2\n0.225\n0.213\n\n\nR2 Adj.\n0.225\n0.213\n\n\nAIC\n401377.8\n401799.2\n\n\nBIC\n401410.8\n401823.9\n\n\nLog.Lik.\n-26951.287\n-27162.944\n\n\nF\n4085.846\n7629.916\n\n\nRMSE\n0.63\n0.63\n\n\n\n* p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\nVCOV swapped\n\nmodelsummary(\n  models = list(\"OLS 1\" = reg3, \"OLS 2\" = reg4),\n  stars  =  c(\"*\" = .05, \"**\" = .01, \"***\" = .001), \n  vcov = list(vcov_reg3, vcov_reg4)\n  )\n\n\n\n\n\n\n\n\nOLS 1\nOLS 2\n\n\n\n(Intercept)\n6.009***\n6.274***\n\n\n\n(0.013)\n(0.004)\n\n\nparttimeyes\n-1.152***\n-1.157***\n\n\n\n(0.015)\n(0.015)\n\n\nethnicitycauc\n0.287***\n\n\n\n\n(0.013)\n\n\n\nNum.Obs.\n28155\n28155\n\n\nR2\n0.225\n0.213\n\n\nR2 Adj.\n0.225\n0.213\n\n\nAIC\n401377.8\n401799.2\n\n\nBIC\n401410.8\n401823.9\n\n\nLog.Lik.\n-26951.287\n-27162.944\n\n\nRMSE\n0.63\n0.63\n\n\nStd.Errors\nCustom\nCustom\n\n\n\n* p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n\n\ncoef_omit lets you omit coefficient rows from the default selections. In the argument, you specify a vector of names or row number of variables you want to omit from the table.\n\ne.g., coef_omit = c(2,3,5) omits the second, third, and fifth coefficients.\n\nExample\nLet’s remove the intercept from the table.\n\n\n\nmodelsummary(\n  models = list(\"OLS 1\" = reg1, \"OLS 2\" = reg2),\n  coef_map = c(\n    \"education\" = \"Education\", \n    \"experience\" = \"Experience\", \n    \"I(experience^2)\" = \"Experience squared\",\n    \"(Intercept)\" = \"Intercept\"\n    ),\n  stars  =  c(\"*\" = .05, \"**\" = .01, \"***\" = .001),\n  coef_omit = 1\n  )\n\n\n\n\n\n\nBy default, the modelsummary() function reports lots of model statistics (e.g., \\(R^2\\), \\(AIC\\), \\(BIC\\)). You can select or omit the model statistics by specifying the gof_map and gof_omit arguments.\n\nYou can see the list of model statistics in modelsummary() by running modelsummary::gof_map \n\n\nExample\nFor example, let’s select only the number of observations, \\(R^2\\), and adjusted \\(R^2\\) using the gof_map argument.\n\n\n\nmodelsummary(\n  models = list(\"OLS 1\" = reg1, \"OLS 2\" = reg2),\n  coef_map = c(\n    \"education\" = \"Education\", \n    \"experience\" = \"Experience\", \n    \"I(experience^2)\" = \"Experience squared\"\n    ),\n  stars  =  c(\"*\" = .05, \"**\" = .01, \"***\" = .001),\n  gof_map = c(\"nobs\", \"r.squared\",  \"adj.r.squared\", \"logLik\")\n  )\n\n\n\n\n\n\n\n\n\nOLS 1\nOLS 2\n\n\n\nEducation\n0.076***\n0.087***\n\n\n\n(0.001)\n(0.001)\n\n\nExperience\n\n0.078***\n\n\n\n\n(0.001)\n\n\nExperience squared\n\n-0.001***\n\n\n\n\n(0.000)\n\n\nNum.Obs.\n28155\n28155\n\n\nR2\n0.095\n0.326\n\n\nR2 Adj.\n0.095\n0.326\n\n\nLog.Lik.\n-29139.853\n-24977.715\n\n\n\n* p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\nnotes lets you add notes at the bottom of the table.\n\nfmt lets you change the format of numbers in the table.\n\nExample\nFor example, let’s select only the number of observations, \\(R^2\\), and adjusted \\(R^2\\) using the gof_map argument.\n\n\nmodelsummary(\n  models = list(\"OLS 1\" = reg1, \"OLS 2\" = reg2),\n  coef_map = c(\n    \"education\" = \"Education\", \n    \"experience\" = \"Experience\", \n    \"I(experience^2)\" = \"Experience squared\"\n    ),\n  stars  =  c(\"*\" = .05, \"**\" = .01, \"***\" = .001),\n  gof_map = c(\"nobs\", \"r.squared\",  \"adj.r.squared\"),\n  notes = list(\"Std. Errors in parentheses\"),\n  fmt = 2 #report the numbers with 2 decimal points\n  )\n\n\n\n\n\n\n\n\nOLS 1\nOLS 2\n\n\n\nEducation\n0.08***\n0.09***\n\n\n\n(0.00)\n(0.00)\n\n\nExperience\n\n0.08***\n\n\n\n\n(0.00)\n\n\nExperience squared\n\n0.00***\n\n\n\n\n(0.00)\n\n\nNum.Obs.\n28155\n28155\n\n\nR2\n0.095\n0.326\n\n\nR2 Adj.\n0.095\n0.326\n\n\n\n\n* p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\nStd. Errors in parentheses"
  },
  {
    "objectID": "Lec4.html#datasummary-function-introduction",
    "href": "Lec4.html#datasummary-function-introduction",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "datasummary() function to report descriptive statistics",
    "text": "datasummary() function to report descriptive statistics\n\nmodelsummary package has another function called datasummary() that can create a summary table for the descriptive statistics of the data.\n\nExample\n\n\ndatasummary(\n  formula = \n    (`Metropolitan area` = smsa) * ( \n      wage + education + experience\n    ) ~ \n    ethnicity * (Mean + SD),\n  data = CPS1988\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetropolitan area\n\n\nafam\n\n\ncauc\n\n\n\nMean\nSD\nMean\nSD\n\n\n\n\nno\nwage\n337.42\n214.57\n527.31\n419.65\n\n\n\neducation\n11.47\n2.78\n12.71\n2.69\n\n\n\nexperience\n19.69\n13.87\n19.05\n13.13\n\n\nyes\nwage\n470.38\n324.97\n649.39\n471.05\n\n\n\neducation\n12.51\n2.73\n13.28\n2.96\n\n\n\nexperience\n18.54\n13.43\n17.83\n12.99"
  },
  {
    "objectID": "Lec4.html#datasummary-function-introduction-1",
    "href": "Lec4.html#datasummary-function-introduction-1",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "datasummary() function: Introduction",
    "text": "datasummary() function: Introduction\n\n\n\nBasics\nExample\nAll()\nIn-class Exercise\n\n\n\ndatasummary() function creates a summary table for the descriptive statistics of the data.\nSyntax\ndatasummary(\n  formula = rows ~ columns,\n  data = dataset\n  )\n\nNote\n\nJust like lm, formula takes a two-side formula devided by ~.\nThe left-hand (right-hand) side of the formula describes the rows (columns).\n\nLet’s see how it works with an example.\n\n\ndatasummary(\n  formula = wage + education + experience ~ Mean + SD,\n  data = CPS1988\n  )\n\n\n\n\n\n\n\n\nMean\nSD\n\n\n\nwage\n603.73\n453.55\n\n\neducation\n13.07\n2.90\n\n\nexperience\n18.20\n13.08\n\n\n\n\n\n\n\nNote\n\nUse + to include more rows and columns.\nThe modelsummary package offers multiple summary functions of its own:\n\n\nMean, SD, Median, Min, Max, P0, P25, P50, P75, P100, Histogram\n\n\n\n\nNA values are automatically stripped before the computation proceeds. So you don’t need to worry about it.\n\n\n\nIn the formula argument, you can use All() function to create a summary table for all the numeric variables in the dataset.\ndatasummary(\n  formula = All(CPS1988)~ Mean + SD,\n  data = CPS1988\n  )\n\n\n\n\n\n\n\n\nMean\nSD\n\n\n\nwage\n603.73\n453.55\n\n\neducation\n13.07\n2.90\n\n\nexperience\n18.20\n13.08\n\n\n\n\n\n\n\n\ndatasummary(\n  formula = wage + education + experience ~ mean + SD,\n  data = CPS1988\n  )\n\n\n\n\n\n\n\n\nmean\nSD\n\n\n\nwage\n603.73\n453.55\n\n\neducation\n13.07\n2.90\n\n\nexperience\n18.20\n13.08\n\n\n\n\n\n\n\nPlay with the datasummary() function:\n\nExchange the rows and columns in the formula and see how the table looks.\nAdd other statistics or variables to the formula and see how the table looks."
  },
  {
    "objectID": "Lec4.html#datasummary-function-further-tuning",
    "href": "Lec4.html#datasummary-function-further-tuning",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "datasummary() Function: Further Tuning",
    "text": "datasummary() Function: Further Tuning\n\n\n\nNesting with * operator\nMultiple Nests\nRenaming the Variables with =\nIn-class Exercise\n\n\n\ndatasummary can nest variables and statistics inside categorical variables using the * symbol. For example, you can display separate means and SD’s for each value of ethnicity.\n\nExample 1: Nested rows\ndatasummary(\n  formula =  ethnicity * (wage + education + experience) ~ mean + SD,\n  data = CPS1988\n  )\n\n\n\n\n\n\n\nethnicity\n\nmean\nSD\n\n\n\nafam\nwage\n446.85\n312.44\n\n\n\neducation\n12.33\n2.77\n\n\n\nexperience\n18.74\n13.51\n\n\ncauc\nwage\n617.23\n461.21\n\n\n\neducation\n13.13\n2.90\n\n\n\nexperience\n18.15\n13.04\n\n\n\n\n\n\n\nExample 2: Nested columns\ndatasummary(\n  formula = wage + education + experience ~ ethnicity * (mean + SD),\n  data = CPS1988\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nafam\n\n\ncauc\n\n\n\nmean\nSD\nmean\nSD\n\n\n\n\nwage\n446.85\n312.44\n617.23\n461.21\n\n\neducation\n12.33\n2.77\n13.13\n2.90\n\n\nexperience\n18.74\n13.51\n18.15\n13.04\n\n\n\n\n\n\n\n\n\nYou can nest variables and statistics inside multiple categorical variables using the * symbol.\nThe order in which terms enter the formula determines the order in which labels are displayed.\n\n\nExample\ndatasummary(\n  formula = wage + education + experience ~ region * ethnicity * (mean + SD),\n  data = CPS1988\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmidwest\n\n\nnortheast\n\n\nsouth\n\n\nwest\n\n\n\n\n\nafam\n\n\ncauc\n\n\nafam\n\n\ncauc\n\n\nafam\n\n\ncauc\n\n\nafam\n\n\ncauc\n\n\n\nmean\nSD\nmean\nSD\nmean\nSD\nmean\nSD\nmean\nSD\nmean\nSD\nmean\nSD\nmean\nSD\n\n\n\n\nwage\n458.32\n312.58\n613.19\n450.94\n505.58\n342.00\n663.04\n438.30\n416.01\n293.52\n582.93\n487.13\n518.20\n346.94\n617.96\n457.77\n\n\neducation\n12.53\n2.62\n13.29\n2.52\n12.28\n2.75\n13.32\n2.77\n12.15\n2.84\n12.91\n3.08\n13.22\n2.38\n13.05\n3.16\n\n\nexperience\n18.53\n13.92\n17.78\n12.90\n20.73\n14.32\n18.69\n13.49\n18.52\n13.22\n18.41\n13.20\n16.89\n12.72\n17.70\n12.48\n\n\n\n\n\n\n\n\n\nBy default, variable and statistics names are used as the labels in the table. You can rename the default labels with the following syntax: (label = variable/statistic).\n\nExample\nBefore renaming:\ndatasummary(\n  formula = wage + education ~ ethnicity * (mean + SD),\n  data = CPS1988\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nafam\n\n\ncauc\n\n\n\nmean\nSD\nmean\nSD\n\n\n\n\nwage\n446.85\n312.44\n617.23\n461.21\n\n\neducation\n12.33\n2.77\n13.13\n2.90\n\n\n\n\n\n\n\nAfter renaming:\ndatasummary(\n  formula = (`Wage (in dollars per week)` = wage) + (`Years of Education` = education) ~ ethnicity * (mean + (`Std.Dev` = SD)),\n  data = CPS1988\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nafam\n\n\ncauc\n\n\n\nmean\nStd.Dev\nmean\nStd.Dev\n\n\n\n\nWage (in dollars per week)\n446.85\n312.44\n617.23\n461.21\n\n\nYears of Education\n12.33\n2.77\n13.13\n2.90\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nIn R, `` is used to define a variable name with spaces or special characters such as the parentheses symbol ().\n\n\n\n\n\n\n\n\nData\nProblem\nAnswers\n\n\n\nFor this exercise problem, we use CPSSW3 dataset from the AER package. The CPSSW3 dataset provides trends (from 1992 to 2004) in hourly earnings in the US of working college graduates aged 25–34 (in 2004 USD).\n\nlibrary(AER)\ndata(\"CPSSW9204\")\nhead(CPSSW9204)\n\n  year  earnings     degree gender age\n1 1992 11.188810   bachelor   male  29\n2 1992 10.000000   bachelor   male  33\n3 1992  5.769231 highschool   male  30\n4 1992  1.562500 highschool   male  32\n5 1992 14.957260   bachelor   male  31\n6 1992  8.660096   bachelor female  26\n\n\n\n\nLet’s create the following tables:\n\nTable 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyear\n\n\nmale\n\n\nfemale\n\n\n\nMean\nSD\nMean\nSD\n\n\n\n\n1992\nearnings\n12.38\n5.88\n10.61\n4.92\n\n\n\nage\n29.74\n2.81\n29.67\n2.81\n\n\n2004\nearnings\n17.77\n9.30\n15.36\n7.71\n\n\n\nage\n29.82\n2.86\n29.67\n2.93\n\n\n\n\n\n\n\nTable 2: Rename some labels in Table 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear\n\n\nmale\n\n\nfemale\n\n\n\nMean\nStd.Dev\nMean\nStd.Dev\n\n\n\n\n1992\nAvg. hourly earnings\n12.38\n5.88\n10.61\n4.92\n\n\n\nAge\n29.74\n2.81\n29.67\n2.81\n\n\n2004\nAvg. hourly earnings\n17.77\n9.30\n15.36\n7.71\n\n\n\nAge\n29.82\n2.86\n29.67\n2.93\n\n\n\n\n\n\n\n\nTable 1\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nTable 2: Rename some labels in Table 1\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "Lec4.html#datasummary_skim",
    "href": "Lec4.html#datasummary_skim",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "datasummary_skim",
    "text": "datasummary_skim\n\n\nBasics\nExample\n\n\n\ndatasummary_skim() with the type = categorical option might be helpful to quickly generate a summary table for categorical variables:\n\nSyntax\ndatasummary_skim(data = dataset, type = \"categorical\")\n\n\n\ndatasummary_skim(data = CPS1988[,.(ethnicity, smsa, region, parttime)], type = \"categorical\")\n\n\n\n\n\n\n\n\n\n\nN\n%\n\n\n\nethnicity\nafam\n2232\n7.9\n\n\n\ncauc\n25923\n92.1\n\n\nsmsa\nno\n7223\n25.7\n\n\n\nyes\n20932\n74.3\n\n\nregion\nmidwest\n6863\n24.4\n\n\n\nnortheast\n6441\n22.9\n\n\n\nsouth\n8760\n31.1\n\n\n\nwest\n6091\n21.6\n\n\nparttime\nno\n25631\n91.0\n\n\n\nyes\n2524\n9.0"
  },
  {
    "objectID": "Lec4.html#datasummary_balance",
    "href": "Lec4.html#datasummary_balance",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "datasummary_balance",
    "text": "datasummary_balance\n\n\nBasics\nExample\n\n\n\ndatasummary_balance() function creates balance tables with summary statistics for different subsets of the data (e.g., control and treatment groups).\n\nSyntax\ndatasummary_balance(\n  formula = variables to summarize ~ group_variable,\n  data = dataset\n  )\n\n\n\ndatasummary_balance(\n  formula = wage + education + experience ~ ethnicity,\n  data = CPS1988,\n  dinm_statistic = \"std.error\" # or \"p.value\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nafam (N=2232)\n\n\ncauc (N=25923)\n\nDiff. in Means\nStd. Error\n\n\nMean\nStd. Dev.\nMean\nStd. Dev.\n\n\n\n\nwage\n446.9\n312.4\n617.2\n461.2\n170.4\n7.2\n\n\neducation\n12.3\n2.8\n13.1\n2.9\n0.8\n0.1\n\n\nexperience\n18.7\n13.5\n18.2\n13.0\n-0.6\n0.3"
  },
  {
    "objectID": "Lec4.html#datasummary_correlation",
    "href": "Lec4.html#datasummary_correlation",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "datasummary_correlation",
    "text": "datasummary_correlation\n\n\nBasics\nExample\n\n\n\ndatasummary_correlation() function creates a correlation table. It automatically identifies all the numeric variables, and calculates the correlation between each of those variables (You don’t need to select the numeric variables manually!).\n\nSyntax\ndatasummary_correlation(data = dataset)\n\n\n\ndatasummary_correlation(data = CPS1988)\n\n\n\n\n\n\n\n\n\nwage\neducation\nexperience\n\n\n\nwage\n1\n.\n.\n\n\neducation\n.30\n1\n.\n\n\nexperience\n.19\n-.29\n1"
  },
  {
    "objectID": "Lec4.html#how-to-create-present-results-in-quarto",
    "href": "Lec4.html#how-to-create-present-results-in-quarto",
    "title": "Day4: Regression Analysis and Reporting Results",
    "section": "How to create present results in Quarto?",
    "text": "How to create present results in Quarto?\n\n\nAfter running some regression models, ultimately you want to report the results in a neat table.\nUsually, we report the regression results in a formatted document like the Rmarkdown or Quarto document (html or PDF).\nSo, let’s practice how to create a summary table for your analysis results in the Quarto document!\nFrom my GuitHub, “materials” under “Data/Materials for Class Use” download and open the document file “practice_modelsummary_html.qmd”.\nSee details here - Documents"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]